!function(e,i){"object"==typeof exports&&"undefined"!=typeof module?i(exports):"function"==typeof define&&define.amd?define(["exports"],i):i((e="undefined"!=typeof globalThis?globalThis:e||self).RadixSort={})}(this,(function(e){"use strict";function i(e,i){(null==i||i>e.length)&&(i=e.length);for(var r=0,t=Array(i);r<i;r++)t[r]=e[r];return t}function r(e,i,r){if("function"==typeof e?e===i:e.has(i))return arguments.length<3?i:r;throw new TypeError("Private element is not present on this object")}function t(e,i){if(!(e instanceof i))throw new TypeError("Cannot call a class as a function")}function n(e,i){(function(e,i){if(i.has(e))throw new TypeError("Cannot initialize the same private elements twice on an object")})(e,i),i.add(e)}function s(e,i){for(var r=0;r<i.length;r++){var t=i[r];t.enumerable=t.enumerable||!1,t.configurable=!0,"value"in t&&(t.writable=!0),Object.defineProperty(e,l(t.key),t)}}function o(e,i,r){return i&&s(e.prototype,i),r&&s(e,r),Object.defineProperty(e,"prototype",{writable:!1}),e}function a(e,i,r){return(i=l(i))in e?Object.defineProperty(e,i,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[i]=r,e}function u(e,i){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);i&&(t=t.filter((function(i){return Object.getOwnPropertyDescriptor(e,i).enumerable}))),r.push.apply(r,t)}return r}function _(e){for(var i=1;i<arguments.length;i++){var r=null!=arguments[i]?arguments[i]:{};i%2?u(Object(r),!0).forEach((function(i){a(e,i,r[i])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):u(Object(r)).forEach((function(i){Object.defineProperty(e,i,Object.getOwnPropertyDescriptor(r,i))}))}return e}function f(e){return function(e){if(Array.isArray(e))return i(e)}(e)||function(e){if("undefined"!=typeof Symbol&&null!=e[Symbol.iterator]||null!=e["@@iterator"])return Array.from(e)}(e)||function(e,r){if(e){if("string"==typeof e)return i(e,r);var t={}.toString.call(e).slice(8,-1);return"Object"===t&&e.constructor&&(t=e.constructor.name),"Map"===t||"Set"===t?Array.from(e):"Arguments"===t||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(t)?i(e,r):void 0}}(e)||function(){throw new TypeError("Invalid attempt to spread non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}()}function l(e){var i=function(e,i){if("object"!=typeof e||!e)return e;var r=e[Symbol.toPrimitive];if(void 0!==r){var t=r.call(e,i||"default");if("object"!=typeof t)return t;throw new TypeError("@@toPrimitive must return a primitive value.")}return("string"===i?String:Number)(e)}(e,"string");return"symbol"==typeof i?i:i+""}function p(e,i){var r={x:i,y:1};if(i>e.limits.maxComputeWorkgroupsPerDimension){var t=Math.floor(Math.sqrt(i)),n=Math.ceil(i/t);r.x=t,r.y=n}return r}function c(e){var i=e.device,r=e.label,t=e.data,n=e.usage,s=void 0===n?0:n,o=i.createBuffer({label:r,usage:s,size:4*t.length,mappedAtCreation:!0});return new Uint32Array(o.getMappedRange()).set(t),o.unmap(),o}var d=function(){return o((function e(i){var r=i.device,n=i.data,s=i.count,o=i.workgroup_size,a=void 0===o?{x:16,y:16}:o,u=i.avoid_bank_conflicts,_=void 0!==u&&u;if(t(this,e),this.device=r,this.workgroup_size=a,this.threads_per_workgroup=a.x*a.y,this.items_per_workgroup=2*this.threads_per_workgroup,Math.log2(this.threads_per_workgroup)%1!=0)throw new Error("workgroup_size.x * workgroup_size.y must be a power of two. (current: ".concat(this.threads_per_workgroup,")"));this.pipelines=[],this.shaderModule=this.device.createShaderModule({label:"prefix-sum",code:_?"\n\n@group(0) @binding(0) var<storage, read_write> items: array<u32>;\n@group(0) @binding(1) var<storage, read_write> blockSums: array<u32>;\n\noverride WORKGROUP_SIZE_X: u32;\noverride WORKGROUP_SIZE_Y: u32;\noverride THREADS_PER_WORKGROUP: u32;\noverride ITEMS_PER_WORKGROUP: u32;\noverride ELEMENT_COUNT: u32;\n\nconst NUM_BANKS: u32 = 32;\nconst LOG_NUM_BANKS: u32 = 5;\n\nfn get_offset(offset: u32) -> u32 {\n    // return offset >> LOG_NUM_BANKS; // Conflict-free\n    return (offset >> NUM_BANKS) + (offset >> (2 * LOG_NUM_BANKS)); // Zero bank conflict\n}\n\nvar<workgroup> temp: array<u32, ITEMS_PER_WORKGROUP*2>;\n\n@compute @workgroup_size(WORKGROUP_SIZE_X, WORKGROUP_SIZE_Y, 1)\nfn reduce_downsweep(\n    @builtin(workgroup_id) w_id: vec3<u32>,\n    @builtin(num_workgroups) w_dim: vec3<u32>,\n    @builtin(local_invocation_index) TID: u32, // Local thread ID\n) {\n    let WORKGROUP_ID = w_id.x + w_id.y * w_dim.x;\n    let WID = WORKGROUP_ID * THREADS_PER_WORKGROUP;\n    let GID = WID + TID; // Global thread ID\n    \n    let ELM_TID = TID * 2; // Element pair local ID\n    let ELM_GID = GID * 2; // Element pair global ID\n    \n    // Load input to shared memory\n    let ai: u32 = TID;\n    let bi: u32 = TID + (ITEMS_PER_WORKGROUP >> 1);\n    let s_ai = ai + get_offset(ai);\n    let s_bi = bi + get_offset(bi);\n    let g_ai = ai + WID * 2;\n    let g_bi = bi + WID * 2;\n    temp[s_ai] = select(items[g_ai], 0, g_ai >= ELEMENT_COUNT);\n    temp[s_bi] = select(items[g_bi], 0, g_bi >= ELEMENT_COUNT);\n\n    var offset: u32 = 1;\n\n    // Up-sweep (reduce) phase\n    for (var d: u32 = ITEMS_PER_WORKGROUP >> 1; d > 0; d >>= 1) {\n        workgroupBarrier();\n\n        if (TID < d) {\n            var ai: u32 = offset * (ELM_TID + 1) - 1;\n            var bi: u32 = offset * (ELM_TID + 2) - 1;\n            ai += get_offset(ai);\n            bi += get_offset(bi);\n            temp[bi] += temp[ai];\n        }\n\n        offset *= 2;\n    }\n\n    // Save workgroup sum and clear last element\n    if (TID == 0) {\n        var last_offset = ITEMS_PER_WORKGROUP - 1;\n        last_offset += get_offset(last_offset);\n\n        blockSums[WORKGROUP_ID] = temp[last_offset];\n        temp[last_offset] = 0;\n    }\n\n    // Down-sweep phase\n    for (var d: u32 = 1; d < ITEMS_PER_WORKGROUP; d *= 2) {\n        offset >>= 1;\n        workgroupBarrier();\n\n        if (TID < d) {\n            var ai: u32 = offset * (ELM_TID + 1) - 1;\n            var bi: u32 = offset * (ELM_TID + 2) - 1;\n            ai += get_offset(ai);\n            bi += get_offset(bi);\n\n            let t: u32 = temp[ai];\n            temp[ai] = temp[bi];\n            temp[bi] += t;\n        }\n    }\n    workgroupBarrier();\n\n    // Copy result from shared memory to global memory\n    if (g_ai < ELEMENT_COUNT) {\n        items[g_ai] = temp[s_ai];\n    }\n    if (g_bi < ELEMENT_COUNT) {\n        items[g_bi] = temp[s_bi];\n    }\n}\n\n@compute @workgroup_size(WORKGROUP_SIZE_X, WORKGROUP_SIZE_Y, 1)\nfn add_block_sums(\n    @builtin(workgroup_id) w_id: vec3<u32>,\n    @builtin(num_workgroups) w_dim: vec3<u32>,\n    @builtin(local_invocation_index) TID: u32, // Local thread ID\n) {\n    let WORKGROUP_ID = w_id.x + w_id.y * w_dim.x;\n    let WID = WORKGROUP_ID * THREADS_PER_WORKGROUP;\n    let GID = WID + TID; // Global thread ID\n\n    let ELM_ID = GID * 2;\n\n    if (ELM_ID >= ELEMENT_COUNT) {\n        return;\n    }\n\n    let blockSum = blockSums[WORKGROUP_ID];\n\n    items[ELM_ID] += blockSum;\n\n    if (ELM_ID + 1 >= ELEMENT_COUNT) {\n        return;\n    }\n\n    items[ELM_ID + 1] += blockSum;\n}":"\n\n@group(0) @binding(0) var<storage, read_write> items: array<u32>;\n@group(0) @binding(1) var<storage, read_write> blockSums: array<u32>;\n\noverride WORKGROUP_SIZE_X: u32;\noverride WORKGROUP_SIZE_Y: u32;\noverride THREADS_PER_WORKGROUP: u32;\noverride ITEMS_PER_WORKGROUP: u32;\noverride ELEMENT_COUNT: u32;\n\nvar<workgroup> temp: array<u32, ITEMS_PER_WORKGROUP*2>;\n\n@compute @workgroup_size(WORKGROUP_SIZE_X, WORKGROUP_SIZE_Y, 1)\nfn reduce_downsweep(\n    @builtin(workgroup_id) w_id: vec3<u32>,\n    @builtin(num_workgroups) w_dim: vec3<u32>,\n    @builtin(local_invocation_index) TID: u32, // Local thread ID\n) {\n    let WORKGROUP_ID = w_id.x + w_id.y * w_dim.x;\n    let WID = WORKGROUP_ID * THREADS_PER_WORKGROUP;\n    let GID = WID + TID; // Global thread ID\n    \n    let ELM_TID = TID * 2; // Element pair local ID\n    let ELM_GID = GID * 2; // Element pair global ID\n    \n    // Load input to shared memory\n    temp[ELM_TID]     = select(items[ELM_GID], 0, ELM_GID >= ELEMENT_COUNT);\n    temp[ELM_TID + 1] = select(items[ELM_GID + 1], 0, ELM_GID + 1 >= ELEMENT_COUNT);\n\n    var offset: u32 = 1;\n\n    // Up-sweep (reduce) phase\n    for (var d: u32 = ITEMS_PER_WORKGROUP >> 1; d > 0; d >>= 1) {\n        workgroupBarrier();\n\n        if (TID < d) {\n            var ai: u32 = offset * (ELM_TID + 1) - 1;\n            var bi: u32 = offset * (ELM_TID + 2) - 1;\n            temp[bi] += temp[ai];\n        }\n\n        offset *= 2;\n    }\n\n    // Save workgroup sum and clear last element\n    if (TID == 0) {\n        let last_offset = ITEMS_PER_WORKGROUP - 1;\n\n        blockSums[WORKGROUP_ID] = temp[last_offset];\n        temp[last_offset] = 0;\n    }\n\n    // Down-sweep phase\n    for (var d: u32 = 1; d < ITEMS_PER_WORKGROUP; d *= 2) {\n        offset >>= 1;\n        workgroupBarrier();\n\n        if (TID < d) {\n            var ai: u32 = offset * (ELM_TID + 1) - 1;\n            var bi: u32 = offset * (ELM_TID + 2) - 1;\n\n            let t: u32 = temp[ai];\n            temp[ai] = temp[bi];\n            temp[bi] += t;\n        }\n    }\n    workgroupBarrier();\n\n    // Copy result from shared memory to global memory\n    if (ELM_GID >= ELEMENT_COUNT) {\n        return;\n    }\n    items[ELM_GID] = temp[ELM_TID];\n\n    if (ELM_GID + 1 >= ELEMENT_COUNT) {\n        return;\n    }\n    items[ELM_GID + 1] = temp[ELM_TID + 1];\n}\n\n@compute @workgroup_size(WORKGROUP_SIZE_X, WORKGROUP_SIZE_Y, 1)\nfn add_block_sums(\n    @builtin(workgroup_id) w_id: vec3<u32>,\n    @builtin(num_workgroups) w_dim: vec3<u32>,\n    @builtin(local_invocation_index) TID: u32, // Local thread ID\n) {\n    let WORKGROUP_ID = w_id.x + w_id.y * w_dim.x;\n    let WID = WORKGROUP_ID * THREADS_PER_WORKGROUP;\n    let GID = WID + TID; // Global thread ID\n\n    let ELM_ID = GID * 2;\n\n    if (ELM_ID >= ELEMENT_COUNT) {\n        return;\n    }\n\n    let blockSum = blockSums[WORKGROUP_ID];\n\n    items[ELM_ID] += blockSum;\n\n    if (ELM_ID + 1 >= ELEMENT_COUNT) {\n        return;\n    }\n\n    items[ELM_ID + 1] += blockSum;\n}"}),this.create_pass_recursive(n,s)}),[{key:"create_pass_recursive",value:function(e,i){var r=Math.ceil(i/this.items_per_workgroup),t=p(this.device,r),n=this.device.createBuffer({label:"prefix-sum-block-sum",size:4*r,usage:GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC|GPUBufferUsage.COPY_DST}),s=this.device.createBindGroupLayout({entries:[{binding:0,visibility:GPUShaderStage.COMPUTE,buffer:{type:"storage"}},{binding:1,visibility:GPUShaderStage.COMPUTE,buffer:{type:"storage"}}]}),o=this.device.createBindGroup({label:"prefix-sum-bind-group",layout:s,entries:[{binding:0,resource:{buffer:e}},{binding:1,resource:{buffer:n}}]}),a=this.device.createPipelineLayout({bindGroupLayouts:[s]}),u=this.device.createComputePipeline({label:"prefix-sum-scan-pipeline",layout:a,compute:{module:this.shaderModule,entryPoint:"reduce_downsweep",constants:{WORKGROUP_SIZE_X:this.workgroup_size.x,WORKGROUP_SIZE_Y:this.workgroup_size.y,THREADS_PER_WORKGROUP:this.threads_per_workgroup,ITEMS_PER_WORKGROUP:this.items_per_workgroup,ELEMENT_COUNT:i}}});if(this.pipelines.push({pipeline:u,bindGroup:o,dispatchSize:t}),r>1){this.create_pass_recursive(n,r);var _=this.device.createComputePipeline({label:"prefix-sum-add-block-pipeline",layout:a,compute:{module:this.shaderModule,entryPoint:"add_block_sums",constants:{WORKGROUP_SIZE_X:this.workgroup_size.x,WORKGROUP_SIZE_Y:this.workgroup_size.y,THREADS_PER_WORKGROUP:this.threads_per_workgroup,ELEMENT_COUNT:i}}});this.pipelines.push({pipeline:_,bindGroup:o,dispatchSize:t})}}},{key:"get_dispatch_chain",value:function(){return this.pipelines.flatMap((function(e){return[e.dispatchSize.x,e.dispatchSize.y,1]}))}},{key:"dispatch",value:function(e,i){for(var r=arguments.length>2&&void 0!==arguments[2]?arguments[2]:0,t=0;t<this.pipelines.length;t++){var n=this.pipelines[t],s=n.pipeline,o=n.bindGroup,a=n.dispatchSize;e.setPipeline(s),e.setBindGroup(0,o),null==i?e.dispatchWorkgroups(a.x,a.y,1):e.dispatchWorkgroupsIndirect(i,r+3*t*4)}}}])}(),h="\n\n@group(0) @binding(0) var<storage, read> inputKeys: array<u32>;\n@group(0) @binding(1) var<storage, read_write> outputKeys: array<u32>;\n@group(0) @binding(2) var<storage, read> local_prefix_sum: array<u32>;\n@group(0) @binding(3) var<storage, read> prefix_block_sum: array<u32>;\n@group(0) @binding(4) var<storage, read> inputValues: array<u32>;\n@group(0) @binding(5) var<storage, read_write> outputValues: array<u32>;\n\noverride WORKGROUP_COUNT: u32;\noverride THREADS_PER_WORKGROUP: u32;\noverride WORKGROUP_SIZE_X: u32;\noverride WORKGROUP_SIZE_Y: u32;\noverride CURRENT_BIT: u32;\noverride ELEMENT_COUNT: u32;\n\n@compute @workgroup_size(WORKGROUP_SIZE_X, WORKGROUP_SIZE_Y, 1)\nfn radix_sort_reorder(\n    @builtin(workgroup_id) w_id: vec3<u32>,\n    @builtin(num_workgroups) w_dim: vec3<u32>,\n    @builtin(local_invocation_index) TID: u32, // Local thread ID\n) { \n    let WORKGROUP_ID = w_id.x + w_id.y * w_dim.x;\n    let WID = WORKGROUP_ID * THREADS_PER_WORKGROUP;\n    let GID = WID + TID; // Global thread ID\n\n    if (GID >= ELEMENT_COUNT) {\n        return;\n    }\n\n    let k = inputKeys[GID];\n    let v = inputValues[GID];\n\n    let local_prefix = local_prefix_sum[GID];\n\n    // Calculate new position\n    let extract_bits = (k >> CURRENT_BIT) & 0x3;\n    let pid = extract_bits * WORKGROUP_COUNT + WORKGROUP_ID;\n    let sorted_position = prefix_block_sum[pid] + local_prefix;\n    \n    outputKeys[sorted_position] = k;\n    outputValues[sorted_position] = v;\n}",b=function(){var e=arguments.length>1&&void 0!==arguments[1]&&arguments[1],i=arguments.length>2&&void 0!==arguments[2]?arguments[2]:"full";return"\n\n@group(0) @binding(0) var<storage, read> input: array<u32>;\n@group(0) @binding(1) var<storage, read_write> output: array<u32>;\n@group(0) @binding(2) var<storage, read> original: array<u32>;\n@group(0) @binding(3) var<storage, read_write> is_sorted: u32;\n\noverride WORKGROUP_SIZE_X: u32;\noverride WORKGROUP_SIZE_Y: u32;\noverride THREADS_PER_WORKGROUP: u32;\noverride ELEMENT_COUNT: u32;\noverride START_ELEMENT: u32;\n\nvar<workgroup> s_data: array<u32, THREADS_PER_WORKGROUP>;\n\n// Reset dispatch buffer and is_sorted flag\n@compute @workgroup_size(WORKGROUP_SIZE_X, WORKGROUP_SIZE_Y, 1)\nfn reset(\n    @builtin(workgroup_id) w_id: vec3<u32>,\n    @builtin(num_workgroups) w_dim: vec3<u32>,\n    @builtin(local_invocation_index) TID: u32, // Local thread ID\n) {\n    if (TID >= ELEMENT_COUNT) {\n        return;\n    }\n\n    if (TID == 0) {\n        is_sorted = 0u;\n    }\n\n    let ELM_ID = TID * 3;\n\n    output[ELM_ID] = original[ELM_ID];\n}\n\n@compute @workgroup_size(WORKGROUP_SIZE_X, WORKGROUP_SIZE_Y, 1)\nfn check_sort(\n    @builtin(workgroup_id) w_id: vec3<u32>,\n    @builtin(num_workgroups) w_dim: vec3<u32>,\n    @builtin(local_invocation_index) TID: u32, // Local thread ID\n) {\n    let WORKGROUP_ID = w_id.x + w_id.y * w_dim.x;\n    let WID = WORKGROUP_ID * THREADS_PER_WORKGROUP + START_ELEMENT;\n    let GID = TID + WID; // Global thread ID\n\n    // Load data into shared memory\n    ".concat(arguments.length>0&&void 0!==arguments[0]&&arguments[0]?g:"s_data[TID] = select(0u, input[GID], GID < ELEMENT_COUNT);","\n\n    // Perform parallel reduction\n    for (var d = 1u; d < THREADS_PER_WORKGROUP; d *= 2u) {      \n        workgroupBarrier();  \n        if (TID % (2u * d) == 0u) {\n            s_data[TID] += s_data[TID + d];\n        }\n    }\n    workgroupBarrier();\n\n    // Write reduction result\n    ").concat(e?R(i):O,"\n}")},O="\n    if (TID == 0) {\n        output[WORKGROUP_ID] = s_data[0];\n    }\n",g="\n    let LAST_THREAD = min(THREADS_PER_WORKGROUP, ELEMENT_COUNT - WID) - 1;\n\n    // Load current element into shared memory\n    // Also load next element for comparison\n    let elm = select(0u, input[GID], GID < ELEMENT_COUNT);\n    let next = select(0u, input[GID + 1], GID < ELEMENT_COUNT-1);\n    s_data[TID] = elm;\n    workgroupBarrier();\n\n    s_data[TID] = select(0u, 1u, GID < ELEMENT_COUNT-1 && elm > next);\n",R=function(e){return"\n    let fullDispatchLength = arrayLength(&output);\n    let dispatchIndex = TID * 3;\n\n    if (dispatchIndex >= fullDispatchLength) {\n        return;\n    }\n\n    ".concat("full"==e?E:m,"\n")},m="\n    output[dispatchIndex] = select(0, original[dispatchIndex], s_data[0] == 0 && is_sorted == 0u);\n",E="\n    if (TID == 0 && s_data[0] == 0) {\n        is_sorted = 1u;\n    }\n\n    output[dispatchIndex] = select(0, original[dispatchIndex], s_data[0] != 0);\n",v=function(){return o((function e(i){var r=i.device,n=i.data,s=i.result,o=i.original,a=i.is_sorted,u=i.count,_=i.start,f=void 0===_?0:_,l=i.mode,p=void 0===l?"full":l,c=i.workgroup_size,d=void 0===c?{x:16,y:16}:c;t(this,e),this.device=r,this.count=u,this.start=f,this.mode=p,this.workgroup_size=d,this.threads_per_workgroup=d.x*d.y,this.pipelines=[],this.buffers={data:n,result:s,original:o,is_sorted:a,outputs:[]},this.create_passes_recursive(n,u)}),[{key:"create_passes_recursive",value:function(e,i){var r=arguments.length>2&&void 0!==arguments[2]?arguments[2]:0,t=Math.ceil(i/this.threads_per_workgroup),n=0===r,s=t<=1,o="check-sort-".concat(this.mode,"-").concat(r),a=s?this.buffers.result:this.device.createBuffer({label:o,size:4*t,usage:GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC|GPUBufferUsage.COPY_DST}),u=this.device.createBindGroupLayout({entries:[{binding:0,visibility:GPUShaderStage.COMPUTE,buffer:{type:"read-only-storage"}},{binding:1,visibility:GPUShaderStage.COMPUTE,buffer:{type:"storage"}}].concat(f(s?[{binding:2,visibility:GPUShaderStage.COMPUTE,buffer:{type:"read-only-storage"}},{binding:3,visibility:GPUShaderStage.COMPUTE,buffer:{type:"storage"}}]:[]))}),l=this.device.createBindGroup({layout:u,entries:[{binding:0,resource:{buffer:e}},{binding:1,resource:{buffer:a}}].concat(f(s?[{binding:2,resource:{buffer:this.buffers.original}},{binding:3,resource:{buffer:this.buffers.is_sorted}}]:[]))}),p=this.device.createPipelineLayout({bindGroupLayouts:[u]}),c=n?this.start+i:i,d=n?this.start:0,h=this.device.createComputePipeline({layout:p,compute:{module:this.device.createShaderModule({label:o,code:b(n,s,this.mode)}),entryPoint:"reset"==this.mode?"reset":"check_sort",constants:_({ELEMENT_COUNT:c,WORKGROUP_SIZE_X:this.workgroup_size.x,WORKGROUP_SIZE_Y:this.workgroup_size.y},"reset"!=this.mode&&{THREADS_PER_WORKGROUP:this.threads_per_workgroup,START_ELEMENT:d})}});this.buffers.outputs.push(a),this.pipelines.push({pipeline:h,bindGroup:l}),s||this.create_passes_recursive(a,t,r+1)}},{key:"dispatch",value:function(e,i){for(var r=arguments.length>2&&void 0!==arguments[2]?arguments[2]:0,t=0;t<this.pipelines.length;t++){var n=this.pipelines[t],s=n.pipeline,o=n.bindGroup,a="reset"!=this.mode&&("full"==this.mode||t<this.pipelines.length-1);e.setPipeline(s),e.setBindGroup(0,o),a?e.dispatchWorkgroupsIndirect(i,r+3*t*4):e.dispatchWorkgroups(1,1,1)}}}],[{key:"find_optimal_dispatch_chain",value:function(e,i,r){var t=r.x*r.y,n=[];do{var s=Math.ceil(i/t),o=p(e,s);n.push(o.x,o.y,1),i=s}while(i>1);return n}}])}(),P=new WeakSet,T=function(){return o((function e(){var i=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},r=i.device,s=i.keys,o=i.values,a=i.count,u=i.bit_count,_=void 0===u?32:u,f=i.workgroup_size,l=void 0===f?{x:16,y:16}:f,p=i.check_order,c=void 0!==p&&p,d=i.local_shuffle,h=void 0!==d&&d,b=i.avoid_bank_conflicts,O=void 0!==b&&b;if(t(this,e),n(this,P),null==r)throw new Error("No device provided");if(null==s)throw new Error("No keys buffer provided");if(!Number.isInteger(a)||a<=0)throw new Error("Invalid count parameter");if(!Number.isInteger(_)||_<=0||_>32)throw new Error("Invalid bit_count parameter: ".concat(_));if(!Number.isInteger(l.x)||!Number.isInteger(l.y))throw new Error("Invalid workgroup_size parameter");if(_%4!=0)throw new Error("bit_count must be a multiple of 4");this.device=r,this.count=a,this.bit_count=_,this.workgroup_size=l,this.check_order=c,this.local_shuffle=h,this.avoid_bank_conflicts=O,this.threads_per_workgroup=l.x*l.y,this.workgroup_count=Math.ceil(a/this.threads_per_workgroup),this.prefix_block_workgroup_count=4*this.workgroup_count,this.has_values=null!=o,this.dispatchSize={},this.shaderModules={},this.kernels={},this.pipelines=[],this.buffers={keys:s,values:o},this.create_shader_modules(),this.create_pipelines()}),[{key:"create_shader_modules",value:function(){var e=function(e){return e.split("\n").filter((function(e){return!e.toLowerCase().includes("values")})).join("\n")},i=this.local_shuffle?"\n\n@group(0) @binding(0) var<storage, read_write> input: array<u32>;\n@group(0) @binding(1) var<storage, read_write> local_prefix_sums: array<u32>;\n@group(0) @binding(2) var<storage, read_write> block_sums: array<u32>;\n@group(0) @binding(3) var<storage, read_write> values: array<u32>;\n\noverride WORKGROUP_COUNT: u32;\noverride THREADS_PER_WORKGROUP: u32;\noverride WORKGROUP_SIZE_X: u32;\noverride WORKGROUP_SIZE_Y: u32;\noverride CURRENT_BIT: u32;\noverride ELEMENT_COUNT: u32;\n\nvar<workgroup> s_prefix_sum: array<u32, 2 * (THREADS_PER_WORKGROUP + 1)>;\nvar<workgroup> s_prefix_sum_scan: array<u32, 4>;\n\n@compute @workgroup_size(WORKGROUP_SIZE_X, WORKGROUP_SIZE_Y, 1)\nfn radix_sort(\n    @builtin(workgroup_id) w_id: vec3<u32>,\n    @builtin(num_workgroups) w_dim: vec3<u32>,\n    @builtin(local_invocation_index) TID: u32, // Local thread ID\n) {\n    let WORKGROUP_ID = w_id.x + w_id.y * w_dim.x;\n    let WID = WORKGROUP_ID * THREADS_PER_WORKGROUP;\n    let GID = WID + TID; // Global thread ID\n\n    // Extract 2 bits from the input\n    var elm: u32 = 0;\n    var val: u32 = 0;\n    if (GID < ELEMENT_COUNT) {\n        elm = input[GID];\n        val = values[GID];\n    }\n    let extract_bits: u32 = (elm >> CURRENT_BIT) & 0x3;\n\n    var bit_prefix_sums = array<u32, 4>(0, 0, 0, 0);\n\n    // If the workgroup is inactive, prevent block_sums buffer update\n    var LAST_THREAD: u32 = 0xffffffff; \n\n    if (WORKGROUP_ID < WORKGROUP_COUNT) {\n        // Otherwise store the index of the last active thread in the workgroup\n        LAST_THREAD = min(THREADS_PER_WORKGROUP, ELEMENT_COUNT - WID) - 1;\n    }\n\n    // Initialize parameters for double-buffering\n    let TPW = THREADS_PER_WORKGROUP + 1;\n    var swapOffset: u32 = 0;\n    var inOffset:  u32 = TID;\n    var outOffset: u32 = TID + TPW;\n\n    // 4-way prefix sum\n    for (var b: u32 = 0; b < 4; b++) {\n        // Initialize local prefix with bitmask\n        let bitmask = select(0u, 1u, extract_bits == b);\n        s_prefix_sum[inOffset + 1] = bitmask;\n        workgroupBarrier();\n\n        var prefix_sum: u32 = 0;\n\n        // Prefix sum\n        for (var offset: u32 = 1; offset < THREADS_PER_WORKGROUP; offset *= 2) {\n            if (TID >= offset) {\n                prefix_sum = s_prefix_sum[inOffset] + s_prefix_sum[inOffset - offset];\n            } else {\n                prefix_sum = s_prefix_sum[inOffset];\n            }\n\n            s_prefix_sum[outOffset] = prefix_sum;\n\n            // Swap buffers\n            outOffset = inOffset;\n            swapOffset = TPW - swapOffset;\n            inOffset = TID + swapOffset;\n            \n            workgroupBarrier();\n        }\n\n        // Store prefix sum for current bit\n        bit_prefix_sums[b] = prefix_sum;\n\n        if (TID == LAST_THREAD) {\n            // Store block sum to global memory\n            let total_sum: u32 = prefix_sum + bitmask;\n            block_sums[b * WORKGROUP_COUNT + WORKGROUP_ID] = total_sum;\n        }\n\n        // Swap buffers\n        outOffset = inOffset;\n        swapOffset = TPW - swapOffset;\n        inOffset = TID + swapOffset;\n    }\n\n    let prefix_sum = bit_prefix_sums[extract_bits];   \n\n    // Scan bit prefix sums\n    if (TID == LAST_THREAD) {\n        var sum: u32 = 0;\n        bit_prefix_sums[extract_bits] += 1;\n        for (var i: u32 = 0; i < 4; i++) {\n            s_prefix_sum_scan[i] = sum;\n            sum += bit_prefix_sums[i];\n        }\n    }\n    workgroupBarrier();\n\n    if (GID < ELEMENT_COUNT) {\n        // Compute new position\n        let new_pos: u32 = prefix_sum + s_prefix_sum_scan[extract_bits];\n\n        // Shuffle elements locally\n        input[WID + new_pos] = elm;\n        values[WID + new_pos] = val;\n        local_prefix_sums[WID + new_pos] = prefix_sum;\n    }\n}":"\n\n@group(0) @binding(0) var<storage, read> input: array<u32>;\n@group(0) @binding(1) var<storage, read_write> local_prefix_sums: array<u32>;\n@group(0) @binding(2) var<storage, read_write> block_sums: array<u32>;\n\noverride WORKGROUP_COUNT: u32;\noverride THREADS_PER_WORKGROUP: u32;\noverride WORKGROUP_SIZE_X: u32;\noverride WORKGROUP_SIZE_Y: u32;\noverride CURRENT_BIT: u32;\noverride ELEMENT_COUNT: u32;\n\nvar<workgroup> s_prefix_sum: array<u32, 2 * (THREADS_PER_WORKGROUP + 1)>;\n\n@compute @workgroup_size(WORKGROUP_SIZE_X, WORKGROUP_SIZE_Y, 1)\nfn radix_sort(\n    @builtin(workgroup_id) w_id: vec3<u32>,\n    @builtin(num_workgroups) w_dim: vec3<u32>,\n    @builtin(local_invocation_index) TID: u32, // Local thread ID\n) {\n    let WORKGROUP_ID = w_id.x + w_id.y * w_dim.x;\n    let WID = WORKGROUP_ID * THREADS_PER_WORKGROUP;\n    let GID = WID + TID; // Global thread ID\n\n    // Extract 2 bits from the input\n    let elm = select(input[GID], 0, GID >= ELEMENT_COUNT);\n    let extract_bits: u32 = (elm >> CURRENT_BIT) & 0x3;\n\n    var bit_prefix_sums = array<u32, 4>(0, 0, 0, 0);\n\n    // If the workgroup is inactive, prevent block_sums buffer update\n    var LAST_THREAD: u32 = 0xffffffff; \n\n    if (WORKGROUP_ID < WORKGROUP_COUNT) {\n        // Otherwise store the index of the last active thread in the workgroup\n        LAST_THREAD = min(THREADS_PER_WORKGROUP, ELEMENT_COUNT - WID) - 1;\n    }\n\n    // Initialize parameters for double-buffering\n    let TPW = THREADS_PER_WORKGROUP + 1;\n    var swapOffset: u32 = 0;\n    var inOffset:  u32 = TID;\n    var outOffset: u32 = TID + TPW;\n\n    // 4-way prefix sum\n    for (var b: u32 = 0; b < 4; b++) {\n        // Initialize local prefix with bitmask\n        let bitmask = select(0u, 1u, extract_bits == b);\n        s_prefix_sum[inOffset + 1] = bitmask;\n        workgroupBarrier();\n\n        var prefix_sum: u32 = 0;\n\n        // Prefix sum\n        for (var offset: u32 = 1; offset < THREADS_PER_WORKGROUP; offset *= 2) {\n            if (TID >= offset) {\n                prefix_sum = s_prefix_sum[inOffset] + s_prefix_sum[inOffset - offset];\n            } else {\n                prefix_sum = s_prefix_sum[inOffset];\n            }\n\n            s_prefix_sum[outOffset] = prefix_sum;\n            \n            // Swap buffers\n            outOffset = inOffset;\n            swapOffset = TPW - swapOffset;\n            inOffset = TID + swapOffset;\n            \n            workgroupBarrier();\n        }\n\n        // Store prefix sum for current bit\n        bit_prefix_sums[b] = prefix_sum;\n\n        if (TID == LAST_THREAD) {\n            // Store block sum to global memory\n            let total_sum: u32 = prefix_sum + bitmask;\n            block_sums[b * WORKGROUP_COUNT + WORKGROUP_ID] = total_sum;\n        }\n\n        // Swap buffers\n        outOffset = inOffset;\n        swapOffset = TPW - swapOffset;\n        inOffset = TID + swapOffset;\n    }\n\n    if (GID < ELEMENT_COUNT) {\n        // Store local prefix sum to global memory\n        local_prefix_sums[GID] = bit_prefix_sums[extract_bits];\n    }\n}";this.shaderModules={blockSum:this.device.createShaderModule({label:"radix-sort-block-sum",code:this.has_values?i:e(i)}),reorder:this.device.createShaderModule({label:"radix-sort-reorder",code:this.has_values?h:e(h)})}}},{key:"create_pipelines",value:function(){this.create_prefix_sum_kernel();var e=this.calculate_dispatch_sizes();this.create_buffers(e),this.create_check_sort_kernels(e);for(var i=0;i<this.bit_count;i+=2){var r=i%4==0,t=r?this.buffers.keys:this.buffers.tmpKeys,n=r?this.buffers.values:this.buffers.tmpValues,s=r?this.buffers.tmpKeys:this.buffers.keys,o=r?this.buffers.tmpValues:this.buffers.values,a=this.create_block_sum_pipeline(t,n,i),u=this.create_reorder_pipeline(t,n,s,o,i);this.pipelines.push({blockSumPipeline:a,reorderPipeline:u})}}},{key:"create_prefix_sum_kernel",value:function(){var e=this.device.createBuffer({label:"radix-sort-prefix-block-sum",size:4*this.prefix_block_workgroup_count,usage:GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC|GPUBufferUsage.COPY_DST}),i=new d({device:this.device,data:e,count:this.prefix_block_workgroup_count,workgroup_size:this.workgroup_size,avoid_bank_conflicts:this.avoid_bank_conflicts});this.kernels.prefixSum=i,this.buffers.prefixBlockSum=e}},{key:"calculate_dispatch_sizes",value:function(){var e=p(this.device,this.workgroup_count),i=this.kernels.prefixSum.get_dispatch_chain(),r=Math.min(this.count,4*this.threads_per_workgroup),t=this.count-r,n=r-1,s=v.find_optimal_dispatch_chain(this.device,r,this.workgroup_size),o=v.find_optimal_dispatch_chain(this.device,t,this.workgroup_size),a=[e.x,e.y,1].concat(f(s.slice(0,3)),f(i));return this.dispatchOffsets={radix_sort:0,check_sort_fast:12,prefix_sum:24},this.dispatchSize=e,this.initialDispatch=a,{initialDispatch:a,dispatchSizesFull:o,check_sort_fast_count:r,check_sort_full_count:t,start_full:n}}},{key:"create_buffers",value:function(e){var i=this.device.createBuffer({label:"radix-sort-tmp-keys",size:4*this.count,usage:GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC|GPUBufferUsage.COPY_DST}),r=this.has_values?this.device.createBuffer({label:"radix-sort-tmp-values",size:4*this.count,usage:GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC|GPUBufferUsage.COPY_DST}):null,t=this.device.createBuffer({label:"radix-sort-local-prefix-sum",size:4*this.count,usage:GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC|GPUBufferUsage.COPY_DST});if(this.buffers.tmpKeys=i,this.buffers.tmpValues=r,this.buffers.localPrefixSum=t,this.check_order){var n=c({device:this.device,label:"radix-sort-dispatch-size",data:e.initialDispatch,usage:GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC|GPUBufferUsage.INDIRECT}),s=c({device:this.device,label:"radix-sort-dispatch-size-original",data:e.initialDispatch,usage:GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC}),o=c({label:"check-sort-full-dispatch-size",device:this.device,data:e.dispatchSizesFull,usage:GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC|GPUBufferUsage.INDIRECT}),a=c({label:"check-sort-full-dispatch-size-original",device:this.device,data:e.dispatchSizesFull,usage:GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC}),u=c({label:"is-sorted",device:this.device,data:new Uint32Array([0]),usage:GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC|GPUBufferUsage.COPY_DST});this.buffers.dispatchSize=n,this.buffers.originalDispatchSize=s,this.buffers.checkSortFullDispatchSize=o,this.buffers.originalCheckSortFullDispatchSize=a,this.buffers.isSorted=u}}},{key:"create_check_sort_kernels",value:function(e){if(this.check_order){var i=e.check_sort_fast_count,r=e.check_sort_full_count,t=e.start_full,n=new v({mode:"full",device:this.device,data:this.buffers.keys,result:this.buffers.dispatchSize,original:this.buffers.originalDispatchSize,is_sorted:this.buffers.isSorted,count:r,start:t,workgroup_size:this.workgroup_size}),s=new v({mode:"fast",device:this.device,data:this.buffers.keys,result:this.buffers.checkSortFullDispatchSize,original:this.buffers.originalCheckSortFullDispatchSize,is_sorted:this.buffers.isSorted,count:i,workgroup_size:this.workgroup_size}),o=this.initialDispatch.length/3;if(s.threads_per_workgroup<n.pipelines.length||n.threads_per_workgroup<o)return console.warn("Warning: workgroup size is too small to enable check sort optimization, disabling..."),void(this.check_order=!1);var a=new v({mode:"reset",device:this.device,data:this.buffers.keys,original:this.buffers.originalDispatchSize,result:this.buffers.dispatchSize,is_sorted:this.buffers.isSorted,count:o,workgroup_size:p(this.device,o)});this.kernels.checkSort={reset:a,fast:s,full:n}}}},{key:"create_block_sum_pipeline",value:function(e,i,r){var t=this.device.createBindGroupLayout({label:"radix-sort-block-sum",entries:[{binding:0,visibility:GPUShaderStage.COMPUTE,buffer:{type:this.local_shuffle?"storage":"read-only-storage"}},{binding:1,visibility:GPUShaderStage.COMPUTE,buffer:{type:"storage"}},{binding:2,visibility:GPUShaderStage.COMPUTE,buffer:{type:"storage"}}].concat(f(this.local_shuffle&&this.has_values?[{binding:3,visibility:GPUShaderStage.COMPUTE,buffer:{type:"storage"}}]:[]))}),n=this.device.createBindGroup({layout:t,entries:[{binding:0,resource:{buffer:e}},{binding:1,resource:{buffer:this.buffers.localPrefixSum}},{binding:2,resource:{buffer:this.buffers.prefixBlockSum}}].concat(f(this.local_shuffle&&this.has_values?[{binding:3,resource:{buffer:i}}]:[]))}),s=this.device.createPipelineLayout({bindGroupLayouts:[t]});return{pipeline:this.device.createComputePipeline({label:"radix-sort-block-sum",layout:s,compute:{module:this.shaderModules.blockSum,entryPoint:"radix_sort",constants:{WORKGROUP_SIZE_X:this.workgroup_size.x,WORKGROUP_SIZE_Y:this.workgroup_size.y,WORKGROUP_COUNT:this.workgroup_count,THREADS_PER_WORKGROUP:this.threads_per_workgroup,ELEMENT_COUNT:this.count,CURRENT_BIT:r}}}),bindGroup:n}}},{key:"create_reorder_pipeline",value:function(e,i,r,t,n){var s=this.device.createBindGroupLayout({label:"radix-sort-reorder",entries:[{binding:0,visibility:GPUShaderStage.COMPUTE,buffer:{type:"read-only-storage"}},{binding:1,visibility:GPUShaderStage.COMPUTE,buffer:{type:"storage"}},{binding:2,visibility:GPUShaderStage.COMPUTE,buffer:{type:"read-only-storage"}},{binding:3,visibility:GPUShaderStage.COMPUTE,buffer:{type:"read-only-storage"}}].concat(f(this.has_values?[{binding:4,visibility:GPUShaderStage.COMPUTE,buffer:{type:"read-only-storage"}},{binding:5,visibility:GPUShaderStage.COMPUTE,buffer:{type:"storage"}}]:[]))}),o=this.device.createBindGroup({layout:s,entries:[{binding:0,resource:{buffer:e}},{binding:1,resource:{buffer:r}},{binding:2,resource:{buffer:this.buffers.localPrefixSum}},{binding:3,resource:{buffer:this.buffers.prefixBlockSum}}].concat(f(this.has_values?[{binding:4,resource:{buffer:i}},{binding:5,resource:{buffer:t}}]:[]))}),a=this.device.createPipelineLayout({bindGroupLayouts:[s]});return{pipeline:this.device.createComputePipeline({label:"radix-sort-reorder",layout:a,compute:{module:this.shaderModules.reorder,entryPoint:"radix_sort_reorder",constants:{WORKGROUP_SIZE_X:this.workgroup_size.x,WORKGROUP_SIZE_Y:this.workgroup_size.y,WORKGROUP_COUNT:this.workgroup_count,THREADS_PER_WORKGROUP:this.threads_per_workgroup,ELEMENT_COUNT:this.count,CURRENT_BIT:n}}}),bindGroup:o}}},{key:"dispatch",value:function(e){this.check_order?r(P,this,U).call(this,e):r(P,this,I).call(this,e)}}])}();function I(e){for(var i=0;i<this.bit_count/2;i++){var r=this.pipelines[i],t=r.blockSumPipeline,n=r.reorderPipeline;e.setPipeline(t.pipeline),e.setBindGroup(0,t.bindGroup),e.dispatchWorkgroups(this.dispatchSize.x,this.dispatchSize.y,1),this.kernels.prefixSum.dispatch(e),e.setPipeline(n.pipeline),e.setBindGroup(0,n.bindGroup),e.dispatchWorkgroups(this.dispatchSize.x,this.dispatchSize.y,1)}}function U(e){this.kernels.checkSort.reset.dispatch(e);for(var i=0;i<this.bit_count/2;i++){var r=this.pipelines[i],t=r.blockSumPipeline,n=r.reorderPipeline;i%2==0&&(this.kernels.checkSort.fast.dispatch(e,this.buffers.dispatchSize,this.dispatchOffsets.check_sort_fast),this.kernels.checkSort.full.dispatch(e,this.buffers.checkSortFullDispatchSize)),e.setPipeline(t.pipeline),e.setBindGroup(0,t.bindGroup),e.dispatchWorkgroupsIndirect(this.buffers.dispatchSize,this.dispatchOffsets.radix_sort),this.kernels.prefixSum.dispatch(e,this.buffers.dispatchSize,this.dispatchOffsets.prefix_sum),e.setPipeline(n.pipeline),e.setBindGroup(0,n.bindGroup),e.dispatchWorkgroupsIndirect(this.buffers.dispatchSize,this.dispatchOffsets.radix_sort)}}e.PrefixSumKernel=d,e.RadixSortKernel=T}));
//# sourceMappingURL=radix-sort-umd.min.js.map
