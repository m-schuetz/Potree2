{"version":3,"file":"radix-sort-umd.min.js","sources":["../../src/utils.js","../../src/PrefixSumKernel.js","../../src/shaders/optimizations/prefix_sum_no_bank_conflict.js","../../src/shaders/prefix_sum.js","../../src/shaders/radix_sort_reorder.js","../../src/shaders/check_sort.js","../../src/CheckSortKernel.js","../../src/RadixSortKernel.js","../../src/shaders/optimizations/radix_sort_local_shuffle.js","../../src/shaders/radix_sort.js"],"sourcesContent":["/**\r\n * Find the best dispatch size x and y dimensions to minimize unused workgroups\r\n * \r\n * @param {GPUDevice} device - The GPU device\r\n * @param {int} workgroup_count - Number of workgroups to dispatch\r\n * @returns \r\n */\r\nfunction find_optimal_dispatch_size(device, workgroup_count) {\r\n    const dispatchSize = { \r\n        x: workgroup_count, \r\n        y: 1\r\n    }\r\n\r\n    if (workgroup_count > device.limits.maxComputeWorkgroupsPerDimension) {\r\n        const x = Math.floor(Math.sqrt(workgroup_count))\r\n        const y = Math.ceil(workgroup_count / x)\r\n        \r\n        dispatchSize.x = x\r\n        dispatchSize.y = y\r\n    }\r\n\r\n    return dispatchSize\r\n}\r\n\r\nfunction create_buffer_from_data({device, label, data, usage = 0}) {\r\n    const dispatchSizes = device.createBuffer({\r\n        label: label,\r\n        usage: usage,\r\n        size: data.length * 4,\r\n        mappedAtCreation: true\r\n    })\r\n\r\n    const dispatchData = new Uint32Array(dispatchSizes.getMappedRange())\r\n    dispatchData.set(data)\r\n    dispatchSizes.unmap()\r\n\r\n    return dispatchSizes\r\n}\r\n\r\nexport {\r\n    find_optimal_dispatch_size,\r\n    create_buffer_from_data,\r\n}","import prefixSumSource from \"./shaders/prefix_sum\"\r\nimport prefixSumSource_NoBankConflict from \"./shaders/optimizations/prefix_sum_no_bank_conflict\"\r\nimport { find_optimal_dispatch_size } from \"./utils\"\r\n\r\nclass PrefixSumKernel {\r\n    /**\r\n     * Perform a parallel prefix sum on the given data buffer\r\n     * \r\n     * Based on \"Parallel Prefix Sum (Scan) with CUDA\"\r\n     * https://www.eecs.umich.edu/courses/eecs570/hw/parprefix.pdf\r\n     * \r\n     * @param {GPUDevice} device\r\n     * @param {GPUBuffer} data - Buffer containing the data to process\r\n     * @param {number} count - Max number of elements to process\r\n     * @param {object} workgroup_size - Workgroup size in x and y dimensions. (x * y) must be a power of two\r\n     * @param {boolean} avoid_bank_conflicts - Use the \"Avoid bank conflicts\" optimization from the original publication\r\n     */\r\n    constructor({\r\n        device,\r\n        data,\r\n        count,\r\n        workgroup_size = { x: 16, y: 16 },\r\n        avoid_bank_conflicts = false\r\n    }) {\r\n        this.device = device\r\n        this.workgroup_size = workgroup_size\r\n        this.threads_per_workgroup = workgroup_size.x * workgroup_size.y\r\n        this.items_per_workgroup = 2 * this.threads_per_workgroup // 2 items are processed per thread\r\n\r\n        if (Math.log2(this.threads_per_workgroup) % 1 !== 0) \r\n            throw new Error(`workgroup_size.x * workgroup_size.y must be a power of two. (current: ${this.threads_per_workgroup})`)\r\n\r\n        this.pipelines = []\r\n\r\n        this.shaderModule = this.device.createShaderModule({\r\n            label: 'prefix-sum',\r\n            code: avoid_bank_conflicts ? prefixSumSource_NoBankConflict : prefixSumSource,\r\n        })\r\n\r\n        this.create_pass_recursive(data, count)\r\n    }\r\n\r\n    create_pass_recursive(data, count) {\r\n        // Find best dispatch x and y dimensions to minimize unused threads\r\n        const workgroup_count = Math.ceil(count / this.items_per_workgroup)\r\n        const dispatchSize = find_optimal_dispatch_size(this.device, workgroup_count)\r\n        \r\n        // Create buffer for block sums        \r\n        const blockSumBuffer = this.device.createBuffer({\r\n            label: 'prefix-sum-block-sum',\r\n            size: workgroup_count * 4,\r\n            usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC | GPUBufferUsage.COPY_DST\r\n        })\r\n\r\n        // Create bind group and pipeline layout\r\n        const bindGroupLayout = this.device.createBindGroupLayout({\r\n            entries: [\r\n                {\r\n                    binding: 0,\r\n                    visibility: GPUShaderStage.COMPUTE,\r\n                    buffer: { type: 'storage' }\r\n                },\r\n                {\r\n                    binding: 1,\r\n                    visibility: GPUShaderStage.COMPUTE,\r\n                    buffer: { type: 'storage' }\r\n                }\r\n            ]\r\n        })\r\n\r\n        const bindGroup = this.device.createBindGroup({\r\n            label: 'prefix-sum-bind-group',\r\n            layout: bindGroupLayout,\r\n            entries: [\r\n                {\r\n                    binding: 0,\r\n                    resource: { buffer: data }\r\n                },\r\n                {\r\n                    binding: 1,\r\n                    resource: { buffer: blockSumBuffer }\r\n                }\r\n            ]\r\n        })\r\n\r\n        const pipelineLayout = this.device.createPipelineLayout({\r\n            bindGroupLayouts: [ bindGroupLayout ]\r\n        })\r\n\r\n        // Per-workgroup (block) prefix sum\r\n        const scanPipeline = this.device.createComputePipeline({\r\n            label: 'prefix-sum-scan-pipeline',\r\n            layout: pipelineLayout,\r\n            compute: {\r\n                module: this.shaderModule,\r\n                entryPoint: 'reduce_downsweep',\r\n                constants: {\r\n                    'WORKGROUP_SIZE_X': this.workgroup_size.x,\r\n                    'WORKGROUP_SIZE_Y': this.workgroup_size.y,\r\n                    'THREADS_PER_WORKGROUP': this.threads_per_workgroup,\r\n                    'ITEMS_PER_WORKGROUP': this.items_per_workgroup,\r\n                    'ELEMENT_COUNT': count,\r\n                }\r\n            }\r\n        })\r\n\r\n        this.pipelines.push({ pipeline: scanPipeline, bindGroup, dispatchSize })\r\n\r\n        if (workgroup_count > 1) {\r\n            // Prefix sum on block sums\r\n            this.create_pass_recursive(blockSumBuffer, workgroup_count)\r\n\r\n            // Add block sums to local prefix sums\r\n            const blockSumPipeline = this.device.createComputePipeline({\r\n                label: 'prefix-sum-add-block-pipeline',\r\n                layout: pipelineLayout,\r\n                compute: {\r\n                    module: this.shaderModule,\r\n                    entryPoint: 'add_block_sums',\r\n                    constants: {\r\n                        'WORKGROUP_SIZE_X': this.workgroup_size.x,\r\n                        'WORKGROUP_SIZE_Y': this.workgroup_size.y,\r\n                        'THREADS_PER_WORKGROUP': this.threads_per_workgroup,\r\n                        'ELEMENT_COUNT': count,\r\n                    }\r\n                }\r\n            })\r\n\r\n            this.pipelines.push({ pipeline: blockSumPipeline, bindGroup, dispatchSize })\r\n        }\r\n    }\r\n\r\n    get_dispatch_chain() {\r\n        return this.pipelines.flatMap(p => [ p.dispatchSize.x, p.dispatchSize.y, 1 ])\r\n    }\r\n\r\n    /**\r\n     * Encode the prefix sum pipeline into the current pass.\r\n     * If dispatchSizeBuffer is provided, the dispatch will be indirect (dispatchWorkgroupsIndirect)\r\n     * \r\n     * @param {GPUComputePassEncoder} pass \r\n     * @param {GPUBuffer} dispatchSizeBuffer - (optional) Indirect dispatch buffer\r\n     * @param {int} offset - (optional) Offset in bytes in the dispatch buffer. Default: 0\r\n     */\r\n    dispatch(pass, dispatchSizeBuffer, offset = 0) {\r\n        for (let i = 0; i < this.pipelines.length; i++) {\r\n            const { pipeline, bindGroup, dispatchSize } = this.pipelines[i]\r\n            \r\n            pass.setPipeline(pipeline)\r\n            pass.setBindGroup(0, bindGroup)\r\n\r\n            if (dispatchSizeBuffer == null)\r\n                pass.dispatchWorkgroups(dispatchSize.x, dispatchSize.y, 1)\r\n            else\r\n                pass.dispatchWorkgroupsIndirect(dispatchSizeBuffer, offset + i * 3 * 4)\r\n        }\r\n    }\r\n}\r\n\r\nexport default PrefixSumKernel","/**\r\n * Prefix sum with optimization to avoid bank conflicts\r\n * \r\n * (see Implementation section in README for details)\r\n */\r\nconst prefixSumNoBankConflictSource = /* wgsl */ `\r\n\r\n@group(0) @binding(0) var<storage, read_write> items: array<u32>;\r\n@group(0) @binding(1) var<storage, read_write> blockSums: array<u32>;\r\n\r\noverride WORKGROUP_SIZE_X: u32;\r\noverride WORKGROUP_SIZE_Y: u32;\r\noverride THREADS_PER_WORKGROUP: u32;\r\noverride ITEMS_PER_WORKGROUP: u32;\r\noverride ELEMENT_COUNT: u32;\r\n\r\nconst NUM_BANKS: u32 = 32;\r\nconst LOG_NUM_BANKS: u32 = 5;\r\n\r\nfn get_offset(offset: u32) -> u32 {\r\n    // return offset >> LOG_NUM_BANKS; // Conflict-free\r\n    return (offset >> NUM_BANKS) + (offset >> (2 * LOG_NUM_BANKS)); // Zero bank conflict\r\n}\r\n\r\nvar<workgroup> temp: array<u32, ITEMS_PER_WORKGROUP*2>;\r\n\r\n@compute @workgroup_size(WORKGROUP_SIZE_X, WORKGROUP_SIZE_Y, 1)\r\nfn reduce_downsweep(\r\n    @builtin(workgroup_id) w_id: vec3<u32>,\r\n    @builtin(num_workgroups) w_dim: vec3<u32>,\r\n    @builtin(local_invocation_index) TID: u32, // Local thread ID\r\n) {\r\n    let WORKGROUP_ID = w_id.x + w_id.y * w_dim.x;\r\n    let WID = WORKGROUP_ID * THREADS_PER_WORKGROUP;\r\n    let GID = WID + TID; // Global thread ID\r\n    \r\n    let ELM_TID = TID * 2; // Element pair local ID\r\n    let ELM_GID = GID * 2; // Element pair global ID\r\n    \r\n    // Load input to shared memory\r\n    let ai: u32 = TID;\r\n    let bi: u32 = TID + (ITEMS_PER_WORKGROUP >> 1);\r\n    let s_ai = ai + get_offset(ai);\r\n    let s_bi = bi + get_offset(bi);\r\n    let g_ai = ai + WID * 2;\r\n    let g_bi = bi + WID * 2;\r\n    temp[s_ai] = select(items[g_ai], 0, g_ai >= ELEMENT_COUNT);\r\n    temp[s_bi] = select(items[g_bi], 0, g_bi >= ELEMENT_COUNT);\r\n\r\n    var offset: u32 = 1;\r\n\r\n    // Up-sweep (reduce) phase\r\n    for (var d: u32 = ITEMS_PER_WORKGROUP >> 1; d > 0; d >>= 1) {\r\n        workgroupBarrier();\r\n\r\n        if (TID < d) {\r\n            var ai: u32 = offset * (ELM_TID + 1) - 1;\r\n            var bi: u32 = offset * (ELM_TID + 2) - 1;\r\n            ai += get_offset(ai);\r\n            bi += get_offset(bi);\r\n            temp[bi] += temp[ai];\r\n        }\r\n\r\n        offset *= 2;\r\n    }\r\n\r\n    // Save workgroup sum and clear last element\r\n    if (TID == 0) {\r\n        var last_offset = ITEMS_PER_WORKGROUP - 1;\r\n        last_offset += get_offset(last_offset);\r\n\r\n        blockSums[WORKGROUP_ID] = temp[last_offset];\r\n        temp[last_offset] = 0;\r\n    }\r\n\r\n    // Down-sweep phase\r\n    for (var d: u32 = 1; d < ITEMS_PER_WORKGROUP; d *= 2) {\r\n        offset >>= 1;\r\n        workgroupBarrier();\r\n\r\n        if (TID < d) {\r\n            var ai: u32 = offset * (ELM_TID + 1) - 1;\r\n            var bi: u32 = offset * (ELM_TID + 2) - 1;\r\n            ai += get_offset(ai);\r\n            bi += get_offset(bi);\r\n\r\n            let t: u32 = temp[ai];\r\n            temp[ai] = temp[bi];\r\n            temp[bi] += t;\r\n        }\r\n    }\r\n    workgroupBarrier();\r\n\r\n    // Copy result from shared memory to global memory\r\n    if (g_ai < ELEMENT_COUNT) {\r\n        items[g_ai] = temp[s_ai];\r\n    }\r\n    if (g_bi < ELEMENT_COUNT) {\r\n        items[g_bi] = temp[s_bi];\r\n    }\r\n}\r\n\r\n@compute @workgroup_size(WORKGROUP_SIZE_X, WORKGROUP_SIZE_Y, 1)\r\nfn add_block_sums(\r\n    @builtin(workgroup_id) w_id: vec3<u32>,\r\n    @builtin(num_workgroups) w_dim: vec3<u32>,\r\n    @builtin(local_invocation_index) TID: u32, // Local thread ID\r\n) {\r\n    let WORKGROUP_ID = w_id.x + w_id.y * w_dim.x;\r\n    let WID = WORKGROUP_ID * THREADS_PER_WORKGROUP;\r\n    let GID = WID + TID; // Global thread ID\r\n\r\n    let ELM_ID = GID * 2;\r\n\r\n    if (ELM_ID >= ELEMENT_COUNT) {\r\n        return;\r\n    }\r\n\r\n    let blockSum = blockSums[WORKGROUP_ID];\r\n\r\n    items[ELM_ID] += blockSum;\r\n\r\n    if (ELM_ID + 1 >= ELEMENT_COUNT) {\r\n        return;\r\n    }\r\n\r\n    items[ELM_ID + 1] += blockSum;\r\n}`\r\n\r\nexport default prefixSumNoBankConflictSource","const prefixSumSource = /* wgsl */ `\r\n\r\n@group(0) @binding(0) var<storage, read_write> items: array<u32>;\r\n@group(0) @binding(1) var<storage, read_write> blockSums: array<u32>;\r\n\r\noverride WORKGROUP_SIZE_X: u32;\r\noverride WORKGROUP_SIZE_Y: u32;\r\noverride THREADS_PER_WORKGROUP: u32;\r\noverride ITEMS_PER_WORKGROUP: u32;\r\noverride ELEMENT_COUNT: u32;\r\n\r\nvar<workgroup> temp: array<u32, ITEMS_PER_WORKGROUP*2>;\r\n\r\n@compute @workgroup_size(WORKGROUP_SIZE_X, WORKGROUP_SIZE_Y, 1)\r\nfn reduce_downsweep(\r\n    @builtin(workgroup_id) w_id: vec3<u32>,\r\n    @builtin(num_workgroups) w_dim: vec3<u32>,\r\n    @builtin(local_invocation_index) TID: u32, // Local thread ID\r\n) {\r\n    let WORKGROUP_ID = w_id.x + w_id.y * w_dim.x;\r\n    let WID = WORKGROUP_ID * THREADS_PER_WORKGROUP;\r\n    let GID = WID + TID; // Global thread ID\r\n    \r\n    let ELM_TID = TID * 2; // Element pair local ID\r\n    let ELM_GID = GID * 2; // Element pair global ID\r\n    \r\n    // Load input to shared memory\r\n    temp[ELM_TID]     = select(items[ELM_GID], 0, ELM_GID >= ELEMENT_COUNT);\r\n    temp[ELM_TID + 1] = select(items[ELM_GID + 1], 0, ELM_GID + 1 >= ELEMENT_COUNT);\r\n\r\n    var offset: u32 = 1;\r\n\r\n    // Up-sweep (reduce) phase\r\n    for (var d: u32 = ITEMS_PER_WORKGROUP >> 1; d > 0; d >>= 1) {\r\n        workgroupBarrier();\r\n\r\n        if (TID < d) {\r\n            var ai: u32 = offset * (ELM_TID + 1) - 1;\r\n            var bi: u32 = offset * (ELM_TID + 2) - 1;\r\n            temp[bi] += temp[ai];\r\n        }\r\n\r\n        offset *= 2;\r\n    }\r\n\r\n    // Save workgroup sum and clear last element\r\n    if (TID == 0) {\r\n        let last_offset = ITEMS_PER_WORKGROUP - 1;\r\n\r\n        blockSums[WORKGROUP_ID] = temp[last_offset];\r\n        temp[last_offset] = 0;\r\n    }\r\n\r\n    // Down-sweep phase\r\n    for (var d: u32 = 1; d < ITEMS_PER_WORKGROUP; d *= 2) {\r\n        offset >>= 1;\r\n        workgroupBarrier();\r\n\r\n        if (TID < d) {\r\n            var ai: u32 = offset * (ELM_TID + 1) - 1;\r\n            var bi: u32 = offset * (ELM_TID + 2) - 1;\r\n\r\n            let t: u32 = temp[ai];\r\n            temp[ai] = temp[bi];\r\n            temp[bi] += t;\r\n        }\r\n    }\r\n    workgroupBarrier();\r\n\r\n    // Copy result from shared memory to global memory\r\n    if (ELM_GID >= ELEMENT_COUNT) {\r\n        return;\r\n    }\r\n    items[ELM_GID] = temp[ELM_TID];\r\n\r\n    if (ELM_GID + 1 >= ELEMENT_COUNT) {\r\n        return;\r\n    }\r\n    items[ELM_GID + 1] = temp[ELM_TID + 1];\r\n}\r\n\r\n@compute @workgroup_size(WORKGROUP_SIZE_X, WORKGROUP_SIZE_Y, 1)\r\nfn add_block_sums(\r\n    @builtin(workgroup_id) w_id: vec3<u32>,\r\n    @builtin(num_workgroups) w_dim: vec3<u32>,\r\n    @builtin(local_invocation_index) TID: u32, // Local thread ID\r\n) {\r\n    let WORKGROUP_ID = w_id.x + w_id.y * w_dim.x;\r\n    let WID = WORKGROUP_ID * THREADS_PER_WORKGROUP;\r\n    let GID = WID + TID; // Global thread ID\r\n\r\n    let ELM_ID = GID * 2;\r\n\r\n    if (ELM_ID >= ELEMENT_COUNT) {\r\n        return;\r\n    }\r\n\r\n    let blockSum = blockSums[WORKGROUP_ID];\r\n\r\n    items[ELM_ID] += blockSum;\r\n\r\n    if (ELM_ID + 1 >= ELEMENT_COUNT) {\r\n        return;\r\n    }\r\n\r\n    items[ELM_ID + 1] += blockSum;\r\n}`\r\n\r\nexport default prefixSumSource","const radixSortReorderSource = /* wgsl */ `\r\n\r\n@group(0) @binding(0) var<storage, read> inputKeys: array<u32>;\r\n@group(0) @binding(1) var<storage, read_write> outputKeys: array<u32>;\r\n@group(0) @binding(2) var<storage, read> local_prefix_sum: array<u32>;\r\n@group(0) @binding(3) var<storage, read> prefix_block_sum: array<u32>;\r\n@group(0) @binding(4) var<storage, read> inputValues: array<u32>;\r\n@group(0) @binding(5) var<storage, read_write> outputValues: array<u32>;\r\n\r\noverride WORKGROUP_COUNT: u32;\r\noverride THREADS_PER_WORKGROUP: u32;\r\noverride WORKGROUP_SIZE_X: u32;\r\noverride WORKGROUP_SIZE_Y: u32;\r\noverride CURRENT_BIT: u32;\r\noverride ELEMENT_COUNT: u32;\r\n\r\n@compute @workgroup_size(WORKGROUP_SIZE_X, WORKGROUP_SIZE_Y, 1)\r\nfn radix_sort_reorder(\r\n    @builtin(workgroup_id) w_id: vec3<u32>,\r\n    @builtin(num_workgroups) w_dim: vec3<u32>,\r\n    @builtin(local_invocation_index) TID: u32, // Local thread ID\r\n) { \r\n    let WORKGROUP_ID = w_id.x + w_id.y * w_dim.x;\r\n    let WID = WORKGROUP_ID * THREADS_PER_WORKGROUP;\r\n    let GID = WID + TID; // Global thread ID\r\n\r\n    if (GID >= ELEMENT_COUNT) {\r\n        return;\r\n    }\r\n\r\n    let k = inputKeys[GID];\r\n    let v = inputValues[GID];\r\n\r\n    let local_prefix = local_prefix_sum[GID];\r\n\r\n    // Calculate new position\r\n    let extract_bits = (k >> CURRENT_BIT) & 0x3;\r\n    let pid = extract_bits * WORKGROUP_COUNT + WORKGROUP_ID;\r\n    let sorted_position = prefix_block_sum[pid] + local_prefix;\r\n    \r\n    outputKeys[sorted_position] = k;\r\n    outputValues[sorted_position] = v;\r\n}`\r\n\r\nexport default radixSortReorderSource;","const checkSortSource = (isFirstPass = false, isLastPass = false, kernelMode = 'full') => /* wgsl */ `\r\n\r\n@group(0) @binding(0) var<storage, read> input: array<u32>;\r\n@group(0) @binding(1) var<storage, read_write> output: array<u32>;\r\n@group(0) @binding(2) var<storage, read> original: array<u32>;\r\n@group(0) @binding(3) var<storage, read_write> is_sorted: u32;\r\n\r\noverride WORKGROUP_SIZE_X: u32;\r\noverride WORKGROUP_SIZE_Y: u32;\r\noverride THREADS_PER_WORKGROUP: u32;\r\noverride ELEMENT_COUNT: u32;\r\noverride START_ELEMENT: u32;\r\n\r\nvar<workgroup> s_data: array<u32, THREADS_PER_WORKGROUP>;\r\n\r\n// Reset dispatch buffer and is_sorted flag\r\n@compute @workgroup_size(WORKGROUP_SIZE_X, WORKGROUP_SIZE_Y, 1)\r\nfn reset(\r\n    @builtin(workgroup_id) w_id: vec3<u32>,\r\n    @builtin(num_workgroups) w_dim: vec3<u32>,\r\n    @builtin(local_invocation_index) TID: u32, // Local thread ID\r\n) {\r\n    if (TID >= ELEMENT_COUNT) {\r\n        return;\r\n    }\r\n\r\n    if (TID == 0) {\r\n        is_sorted = 0u;\r\n    }\r\n\r\n    let ELM_ID = TID * 3;\r\n\r\n    output[ELM_ID] = original[ELM_ID];\r\n}\r\n\r\n@compute @workgroup_size(WORKGROUP_SIZE_X, WORKGROUP_SIZE_Y, 1)\r\nfn check_sort(\r\n    @builtin(workgroup_id) w_id: vec3<u32>,\r\n    @builtin(num_workgroups) w_dim: vec3<u32>,\r\n    @builtin(local_invocation_index) TID: u32, // Local thread ID\r\n) {\r\n    let WORKGROUP_ID = w_id.x + w_id.y * w_dim.x;\r\n    let WID = WORKGROUP_ID * THREADS_PER_WORKGROUP + START_ELEMENT;\r\n    let GID = TID + WID; // Global thread ID\r\n\r\n    // Load data into shared memory\r\n    ${ isFirstPass ? first_pass_load_data : \"s_data[TID] = select(0u, input[GID], GID < ELEMENT_COUNT);\" }\r\n\r\n    // Perform parallel reduction\r\n    for (var d = 1u; d < THREADS_PER_WORKGROUP; d *= 2u) {      \r\n        workgroupBarrier();  \r\n        if (TID % (2u * d) == 0u) {\r\n            s_data[TID] += s_data[TID + d];\r\n        }\r\n    }\r\n    workgroupBarrier();\r\n\r\n    // Write reduction result\r\n    ${ isLastPass ? last_pass(kernelMode) : write_reduction_result }\r\n}`\r\n\r\nconst write_reduction_result = /* wgsl */ `\r\n    if (TID == 0) {\r\n        output[WORKGROUP_ID] = s_data[0];\r\n    }\r\n`\r\n\r\nconst first_pass_load_data = /* wgsl */ `\r\n    let LAST_THREAD = min(THREADS_PER_WORKGROUP, ELEMENT_COUNT - WID) - 1;\r\n\r\n    // Load current element into shared memory\r\n    // Also load next element for comparison\r\n    let elm = select(0u, input[GID], GID < ELEMENT_COUNT);\r\n    let next = select(0u, input[GID + 1], GID < ELEMENT_COUNT-1);\r\n    s_data[TID] = elm;\r\n    workgroupBarrier();\r\n\r\n    s_data[TID] = select(0u, 1u, GID < ELEMENT_COUNT-1 && elm > next);\r\n`\r\n\r\nconst last_pass = (kernelMode) => /* wgsl */ `\r\n    let fullDispatchLength = arrayLength(&output);\r\n    let dispatchIndex = TID * 3;\r\n\r\n    if (dispatchIndex >= fullDispatchLength) {\r\n        return;\r\n    }\r\n\r\n    ${kernelMode == 'full' ? last_pass_full : last_pass_fast}\r\n`\r\n\r\n// If the fast check kernel is sorted and the data isn't already sorted, run the full check\r\nconst last_pass_fast = /* wgsl */ `\r\n    output[dispatchIndex] = select(0, original[dispatchIndex], s_data[0] == 0 && is_sorted == 0u);\r\n`\r\n\r\n// If the full check kernel is sorted, set the flag to 1 and skip radix sort passes\r\nconst last_pass_full = /* wgsl */ `\r\n    if (TID == 0 && s_data[0] == 0) {\r\n        is_sorted = 1u;\r\n    }\r\n\r\n    output[dispatchIndex] = select(0, original[dispatchIndex], s_data[0] != 0);\r\n`\r\nexport default checkSortSource","import checkSortSource from \"./shaders/check_sort\"\r\nimport { find_optimal_dispatch_size } from \"./utils\"\r\n\r\nclass CheckSortKernel {\r\n    /**\r\n     * CheckSortKernel - Performs a parralel reduction to check if an array is sorted.\r\n     * \r\n     * @param {GPUDevice} device\r\n     * @param {GPUBuffer} data - The buffer containing the data to check\r\n     * @param {GPUBuffer} result - The result dispatch size buffer\r\n     * @param {GPUBuffer} original - The original dispatch size buffer\r\n     * @param {GPUBuffer} is_sorted - 1-element buffer to store whether the array is sorted\r\n     * @param {number} count - The number of elements to check\r\n     * @param {number} start - The index to start checking from\r\n     * @param {boolean} mode - The type of check sort kernel ('reset', 'fast', 'full')\r\n     * @param {object} workgroup_size - The workgroup size in x and y dimensions\r\n     */\r\n    constructor({\r\n        device,\r\n        data,\r\n        result,\r\n        original,\r\n        is_sorted,\r\n        count,\r\n        start = 0,\r\n        mode = 'full',\r\n        workgroup_size = { x: 16, y: 16 },\r\n    }) {\r\n        this.device = device\r\n        this.count = count\r\n        this.start = start\r\n        this.mode = mode\r\n        this.workgroup_size = workgroup_size\r\n        this.threads_per_workgroup = workgroup_size.x * workgroup_size.y\r\n\r\n        this.pipelines = []\r\n\r\n        this.buffers = {\r\n            data, \r\n            result, \r\n            original, \r\n            is_sorted,\r\n            outputs: []\r\n        }\r\n\r\n        this.create_passes_recursive(data, count)\r\n    }\r\n\r\n    // Find the best dispatch size for each pass to minimize unused workgroups\r\n    static find_optimal_dispatch_chain(device, item_count, workgroup_size) {\r\n        const threads_per_workgroup = workgroup_size.x * workgroup_size.y\r\n        const sizes = []\r\n\r\n        do {\r\n            // Number of workgroups required to process all items\r\n            const target_workgroup_count = Math.ceil(item_count / threads_per_workgroup)\r\n    \r\n            // Optimal dispatch size and updated workgroup count\r\n            const dispatchSize = find_optimal_dispatch_size(device, target_workgroup_count)\r\n    \r\n            sizes.push(dispatchSize.x, dispatchSize.y, 1)\r\n            item_count = target_workgroup_count\r\n        } while (item_count > 1)\r\n    \r\n        return sizes\r\n    }\r\n\r\n    create_passes_recursive(buffer, count, passIndex = 0) {\r\n        const workgroup_count = Math.ceil(count / this.threads_per_workgroup)\r\n\r\n        const isFirstPass = passIndex === 0\r\n        const isLastPass = workgroup_count <= 1\r\n\r\n        const label = `check-sort-${this.mode}-${passIndex}`\r\n\r\n        const outputBuffer = isLastPass ? this.buffers.result : this.device.createBuffer({\r\n            label: label,\r\n            size: workgroup_count * 4,\r\n            usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC | GPUBufferUsage.COPY_DST\r\n        })\r\n\r\n        const bindGroupLayout = this.device.createBindGroupLayout({\r\n            entries: [\r\n                {\r\n                    binding: 0,\r\n                    visibility: GPUShaderStage.COMPUTE,\r\n                    buffer: { type: 'read-only-storage' }\r\n                },\r\n                {\r\n                    binding: 1,\r\n                    visibility: GPUShaderStage.COMPUTE,\r\n                    buffer: { type: 'storage' }\r\n                },\r\n                // Last pass bindings\r\n                ...(isLastPass ? [{\r\n                    binding: 2,\r\n                    visibility: GPUShaderStage.COMPUTE,\r\n                    buffer: { type: 'read-only-storage' }\r\n                }, {\r\n                    binding: 3,\r\n                    visibility: GPUShaderStage.COMPUTE,\r\n                    buffer: { type: 'storage' }\r\n                }] : []),\r\n            ]\r\n        })\r\n\r\n        const bindGroup = this.device.createBindGroup({\r\n            layout: bindGroupLayout,\r\n            entries: [\r\n                {\r\n                    binding: 0,\r\n                    resource: { buffer: buffer }\r\n                },\r\n                {\r\n                    binding: 1,\r\n                    resource: { buffer: outputBuffer }\r\n                },\r\n                // Last pass buffers\r\n                ...(isLastPass ? [{\r\n                    binding: 2,\r\n                    resource: { buffer: this.buffers.original }\r\n                }, {\r\n                    binding: 3,\r\n                    resource: { buffer: this.buffers.is_sorted }\r\n                }] : []),\r\n            ]\r\n        })\r\n\r\n        const pipelineLayout = this.device.createPipelineLayout({\r\n            bindGroupLayouts: [bindGroupLayout]\r\n        })\r\n\r\n        const element_count = isFirstPass ? this.start + count : count\r\n        const start_element = isFirstPass ? this.start : 0\r\n\r\n        const checkSortPipeline = this.device.createComputePipeline({\r\n            layout: pipelineLayout,\r\n            compute: {\r\n                module: this.device.createShaderModule({\r\n                    label: label,\r\n                    code: checkSortSource(isFirstPass, isLastPass, this.mode),\r\n                }),\r\n                entryPoint: this.mode == 'reset' ? 'reset' : 'check_sort',\r\n                constants: {\r\n                    'ELEMENT_COUNT': element_count,\r\n                    'WORKGROUP_SIZE_X': this.workgroup_size.x,\r\n                    'WORKGROUP_SIZE_Y': this.workgroup_size.y,\r\n                    ...(this.mode != 'reset' && { \r\n                        'THREADS_PER_WORKGROUP': this.threads_per_workgroup,\r\n                        'START_ELEMENT': start_element,\r\n                    })\r\n                },\r\n            }\r\n        })\r\n\r\n        this.buffers.outputs.push(outputBuffer)\r\n        this.pipelines.push({ pipeline: checkSortPipeline, bindGroup })\r\n        \r\n        if (!isLastPass) {\r\n            this.create_passes_recursive(outputBuffer, workgroup_count, passIndex + 1)\r\n        }\r\n    }\r\n\r\n    dispatch(pass, dispatchSize, offset = 0) {\r\n        for (let i = 0; i < this.pipelines.length; i++) {\r\n            const { pipeline, bindGroup } = this.pipelines[i]\r\n\r\n            const dispatchIndirect = this.mode != 'reset' && (this.mode == 'full' || i < this.pipelines.length - 1)\r\n\r\n            pass.setPipeline(pipeline)\r\n            pass.setBindGroup(0, bindGroup)\r\n\r\n            if (dispatchIndirect)\r\n                pass.dispatchWorkgroupsIndirect(dispatchSize, offset + i * 3 * 4)\r\n            else\r\n                // Only the reset kernel and the last dispatch of the fast check kernel are constant to (1, 1, 1)\r\n                pass.dispatchWorkgroups(1, 1, 1)\r\n        }\r\n    }\r\n}\r\n\r\nexport default CheckSortKernel","import PrefixSumKernel from \"./PrefixSumKernel\"\r\nimport radixSortSource from \"./shaders/radix_sort\"\r\nimport radixSortSource_LocalShuffle from \"./shaders/optimizations/radix_sort_local_shuffle\"\r\nimport reorderSource from \"./shaders/radix_sort_reorder\"\r\nimport CheckSortKernel from \"./CheckSortKernel\"\r\nimport { create_buffer_from_data, find_optimal_dispatch_size } from \"./utils\"\r\n\r\nclass RadixSortKernel {\r\n    /**\r\n     * Perform a parallel radix sort on the GPU given a buffer of keys and (optionnaly) values\r\n     * Note: The buffers are sorted in-place.\r\n     * \r\n     * Based on \"Fast 4-way parallel radix sorting on GPUs\"\r\n     * https://www.sci.utah.edu/~csilva/papers/cgf.pdf]\r\n     * \r\n     * @param {GPUDevice} device\r\n     * @param {GPUBuffer} keys - Buffer containing the keys to sort\r\n     * @param {GPUBuffer} values - (optional) Buffer containing the associated values\r\n     * @param {number} count - Number of elements to sort\r\n     * @param {number} bit_count - Number of bits per element (default: 32)\r\n     * @param {object} workgroup_size - Workgroup size in x and y dimensions. (x * y) must be a power of two\r\n     * @param {boolean} check_order - Enable \"order checking\" optimization. Can improve performance if the data needs to be sorted in real-time and doesn't change much. (default: false)\r\n     * @param {boolean} local_shuffle - Enable \"local shuffling\" optimization for the radix sort kernel (default: false)\r\n     * @param {boolean} avoid_bank_conflicts - Enable \"avoiding bank conflicts\" optimization for the prefix sum kernel (default: false)\r\n     */\r\n    constructor({\r\n        device,\r\n        keys,\r\n        values,\r\n        count,\r\n        bit_count = 32,\r\n        workgroup_size = { x: 16, y: 16 },\r\n        check_order = false,\r\n        local_shuffle = false,\r\n        avoid_bank_conflicts = false,\r\n    } = {}) {\r\n        if (device == null) throw new Error('No device provided')\r\n        if (keys == null) throw new Error('No keys buffer provided')\r\n        if (!Number.isInteger(count) || count <= 0) throw new Error('Invalid count parameter')\r\n        if (!Number.isInteger(bit_count) || bit_count <= 0 || bit_count > 32) throw new Error(`Invalid bit_count parameter: ${bit_count}`)\r\n        if (!Number.isInteger(workgroup_size.x) || !Number.isInteger(workgroup_size.y)) throw new Error('Invalid workgroup_size parameter')\r\n        if (bit_count % 4 != 0) throw new Error('bit_count must be a multiple of 4')\r\n\r\n        this.device = device\r\n        this.count = count\r\n        this.bit_count = bit_count\r\n        this.workgroup_size = workgroup_size\r\n        this.check_order = check_order\r\n        this.local_shuffle = local_shuffle\r\n        this.avoid_bank_conflicts = avoid_bank_conflicts\r\n\r\n        this.threads_per_workgroup = workgroup_size.x * workgroup_size.y\r\n        this.workgroup_count = Math.ceil(count / this.threads_per_workgroup)\r\n        this.prefix_block_workgroup_count = 4 * this.workgroup_count\r\n\r\n        this.has_values = (values != null) // Is the values buffer provided ?\r\n\r\n        this.dispatchSize = {}  // Dispatch dimension x and y\r\n        this.shaderModules = {} // GPUShaderModules\r\n        this.kernels = {}       // PrefixSumKernel & CheckSortKernels\r\n        this.pipelines = []     // List of passes\r\n        this.buffers = {        // GPUBuffers\r\n            keys: keys,\r\n            values: values\r\n        }       \r\n\r\n        // Create shader modules from wgsl code\r\n        this.create_shader_modules()\r\n        \r\n        // Create multi-pass pipelines\r\n        this.create_pipelines()\r\n    }\r\n\r\n    create_shader_modules() {\r\n        // Remove every occurence of \"values\" in the shader code if values buffer is not provided\r\n        const remove_values = (source) => {\r\n            return source.split('\\n')\r\n                         .filter(line => !line.toLowerCase().includes('values'))\r\n                         .join('\\n')\r\n        }\r\n\r\n        const blockSumSource = this.local_shuffle ? radixSortSource_LocalShuffle : radixSortSource\r\n        \r\n        this.shaderModules = {\r\n            blockSum: this.device.createShaderModule({\r\n                label: 'radix-sort-block-sum',\r\n                code: this.has_values ? blockSumSource : remove_values(blockSumSource),\r\n            }),\r\n            reorder: this.device.createShaderModule({\r\n                label: 'radix-sort-reorder',\r\n                code: this.has_values ? reorderSource : remove_values(reorderSource),\r\n            })\r\n        }\r\n    }\r\n\r\n    create_pipelines() {    \r\n        // Block prefix sum kernel    \r\n        this.create_prefix_sum_kernel()\r\n\r\n        // Indirect dispatch buffers\r\n        const dispatchData = this.calculate_dispatch_sizes()\r\n\r\n        // GPU buffers\r\n        this.create_buffers(dispatchData)\r\n\r\n        // Check sort kernels\r\n        this.create_check_sort_kernels(dispatchData)\r\n\r\n        // Radix sort passes for every 2 bits\r\n        for (let bit = 0; bit < this.bit_count; bit += 2) {\r\n            // Swap buffers every pass\r\n            const even      = (bit % 4 == 0)\r\n            const inKeys    = even ? this.buffers.keys : this.buffers.tmpKeys\r\n            const inValues  = even ? this.buffers.values : this.buffers.tmpValues\r\n            const outKeys   = even ? this.buffers.tmpKeys : this.buffers.keys\r\n            const outValues = even ? this.buffers.tmpValues : this.buffers.values\r\n\r\n            // Compute local prefix sums and block sums\r\n            const blockSumPipeline = this.create_block_sum_pipeline(inKeys, inValues, bit)\r\n            \r\n            // Reorder keys and values\r\n            const reorderPipeline = this.create_reorder_pipeline(inKeys, inValues, outKeys, outValues, bit)\r\n\r\n            this.pipelines.push({ blockSumPipeline, reorderPipeline })\r\n        }\r\n    }\r\n\r\n    create_prefix_sum_kernel() {\r\n        // Prefix Block Sum buffer (4 element per workgroup)\r\n        const prefixBlockSumBuffer = this.device.createBuffer({\r\n            label: 'radix-sort-prefix-block-sum',\r\n            size: this.prefix_block_workgroup_count * 4,\r\n            usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC | GPUBufferUsage.COPY_DST\r\n        })\r\n\r\n        // Create block prefix sum kernel\r\n        const prefixSumKernel = new PrefixSumKernel({ \r\n            device: this.device,\r\n            data: prefixBlockSumBuffer, \r\n            count: this.prefix_block_workgroup_count,\r\n            workgroup_size: this.workgroup_size,\r\n            avoid_bank_conflicts: this.avoid_bank_conflicts,\r\n        })\r\n\r\n        this.kernels.prefixSum = prefixSumKernel\r\n        this.buffers.prefixBlockSum = prefixBlockSumBuffer\r\n    }\r\n\r\n    calculate_dispatch_sizes() {\r\n        // Radix sort dispatch size\r\n        const dispatchSize = find_optimal_dispatch_size(this.device, this.workgroup_count)\r\n\r\n        // Prefix sum dispatch sizes\r\n        const prefixSumDispatchSize = this.kernels.prefixSum.get_dispatch_chain()\r\n\r\n        // Check sort element count (fast/full)\r\n        const check_sort_fast_count = Math.min(this.count, this.threads_per_workgroup * 4)\r\n        const check_sort_full_count = this.count - check_sort_fast_count\r\n        const start_full = check_sort_fast_count - 1\r\n\r\n        // Check sort dispatch sizes\r\n        const dispatchSizesFast = CheckSortKernel.find_optimal_dispatch_chain(this.device, check_sort_fast_count, this.workgroup_size)\r\n        const dispatchSizesFull = CheckSortKernel.find_optimal_dispatch_chain(this.device, check_sort_full_count, this.workgroup_size)\r\n\r\n        // Initial dispatch sizes\r\n        const initialDispatch = [\r\n            dispatchSize.x, dispatchSize.y, 1, // Radix Sort + Reorder\r\n            ...dispatchSizesFast.slice(0, 3),  // Check sort fast\r\n            ...prefixSumDispatchSize           // Prefix Sum\r\n        ]\r\n\r\n        // Dispatch offsets in main buffer\r\n        this.dispatchOffsets = {\r\n            radix_sort: 0,\r\n            check_sort_fast: 3 * 4,\r\n            prefix_sum: 6 * 4\r\n        }\r\n\r\n        this.dispatchSize = dispatchSize\r\n        this.initialDispatch = initialDispatch\r\n\r\n        return {\r\n            initialDispatch,\r\n            dispatchSizesFull,\r\n            check_sort_fast_count, \r\n            check_sort_full_count, \r\n            start_full \r\n        }\r\n    }\r\n\r\n    create_buffers(dispatchData) {\r\n        // Keys and values double buffering\r\n        const tmpKeysBuffer = this.device.createBuffer({\r\n            label: 'radix-sort-tmp-keys',\r\n            size: this.count * 4,\r\n            usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC | GPUBufferUsage.COPY_DST\r\n        })\r\n        const tmpValuesBuffer = !this.has_values ? null : this.device.createBuffer({\r\n            label: 'radix-sort-tmp-values',\r\n            size: this.count * 4,\r\n            usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC | GPUBufferUsage.COPY_DST\r\n        })\r\n\r\n        // Local Prefix Sum buffer (1 element per item)\r\n        const localPrefixSumBuffer = this.device.createBuffer({\r\n            label: 'radix-sort-local-prefix-sum',\r\n            size: this.count * 4,\r\n            usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC | GPUBufferUsage.COPY_DST\r\n        })\r\n\r\n        this.buffers.tmpKeys = tmpKeysBuffer\r\n        this.buffers.tmpValues = tmpValuesBuffer\r\n        this.buffers.localPrefixSum = localPrefixSumBuffer\r\n\r\n        // Only create indirect dispatch buffers when check_order optimization is enabled\r\n        if (!this.check_order) {\r\n            return\r\n        }\r\n\r\n        // Dispatch sizes (radix sort, check sort, prefix sum)\r\n        const dispatchBuffer = create_buffer_from_data({\r\n            device: this.device, \r\n            label: 'radix-sort-dispatch-size',\r\n            data: dispatchData.initialDispatch, \r\n            usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC | GPUBufferUsage.INDIRECT\r\n        })\r\n        const originalDispatchBuffer = create_buffer_from_data({\r\n            device: this.device, \r\n            label: 'radix-sort-dispatch-size-original',\r\n            data: dispatchData.initialDispatch, \r\n            usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC\r\n        })\r\n\r\n        // Dispatch sizes (full sort)\r\n        const checkSortFullDispatchBuffer = create_buffer_from_data({\r\n            label: 'check-sort-full-dispatch-size',\r\n            device: this.device, \r\n            data: dispatchData.dispatchSizesFull,\r\n            usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC | GPUBufferUsage.INDIRECT\r\n        })\r\n        const checkSortFullOriginalDispatchBuffer = create_buffer_from_data({\r\n            label: 'check-sort-full-dispatch-size-original',\r\n            device: this.device, \r\n            data: dispatchData.dispatchSizesFull,\r\n            usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC\r\n        })\r\n\r\n        // Flag to tell if the data is sorted\r\n        const isSortedBuffer = create_buffer_from_data({\r\n            label: 'is-sorted',\r\n            device: this.device, \r\n            data: new Uint32Array([0]), \r\n            usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC | GPUBufferUsage.COPY_DST\r\n        })\r\n\r\n        this.buffers.dispatchSize = dispatchBuffer\r\n        this.buffers.originalDispatchSize = originalDispatchBuffer\r\n        this.buffers.checkSortFullDispatchSize = checkSortFullDispatchBuffer\r\n        this.buffers.originalCheckSortFullDispatchSize = checkSortFullOriginalDispatchBuffer\r\n        this.buffers.isSorted = isSortedBuffer\r\n    }\r\n\r\n    create_check_sort_kernels(checkSortPartitionData) {\r\n        if (!this.check_order) {\r\n            return\r\n        }\r\n\r\n        const { check_sort_fast_count, check_sort_full_count, start_full } = checkSortPartitionData\r\n\r\n        // Create the full pass\r\n        const checkSortFull = new CheckSortKernel({\r\n            mode: 'full',\r\n            device: this.device,\r\n            data: this.buffers.keys,\r\n            result: this.buffers.dispatchSize,\r\n            original: this.buffers.originalDispatchSize,\r\n            is_sorted: this.buffers.isSorted,\r\n            count: check_sort_full_count,\r\n            start: start_full,\r\n            workgroup_size: this.workgroup_size\r\n        })\r\n\r\n        // Create the fast pass\r\n        const checkSortFast = new CheckSortKernel({\r\n            mode: 'fast',\r\n            device: this.device,\r\n            data: this.buffers.keys,\r\n            result: this.buffers.checkSortFullDispatchSize,\r\n            original: this.buffers.originalCheckSortFullDispatchSize,\r\n            is_sorted: this.buffers.isSorted,\r\n            count: check_sort_fast_count,\r\n            workgroup_size: this.workgroup_size\r\n        })\r\n\r\n        const initialDispatchElementCount = this.initialDispatch.length / 3\r\n\r\n        if (checkSortFast.threads_per_workgroup < checkSortFull.pipelines.length || checkSortFull.threads_per_workgroup < initialDispatchElementCount) {\r\n            console.warn(`Warning: workgroup size is too small to enable check sort optimization, disabling...`)\r\n            this.check_order = false\r\n            return\r\n        }\r\n\r\n        // Create the reset pass\r\n        const checkSortReset = new CheckSortKernel({\r\n            mode: 'reset',\r\n            device: this.device,\r\n            data: this.buffers.keys,\r\n            original: this.buffers.originalDispatchSize,\r\n            result: this.buffers.dispatchSize,\r\n            is_sorted: this.buffers.isSorted,\r\n            count: initialDispatchElementCount,\r\n            workgroup_size: find_optimal_dispatch_size(this.device, initialDispatchElementCount)\r\n        })\r\n\r\n        this.kernels.checkSort = {\r\n            reset: checkSortReset,\r\n            fast: checkSortFast,\r\n            full: checkSortFull,\r\n        }\r\n    }\r\n\r\n    create_block_sum_pipeline(inKeys, inValues, bit) {\r\n        const bindGroupLayout = this.device.createBindGroupLayout({\r\n            label: 'radix-sort-block-sum',\r\n            entries: [\r\n                {\r\n                    binding: 0,\r\n                    visibility: GPUShaderStage.COMPUTE,\r\n                    buffer: { type: this.local_shuffle ? 'storage' : 'read-only-storage' }\r\n                },\r\n                {\r\n                    binding: 1,\r\n                    visibility: GPUShaderStage.COMPUTE,\r\n                    buffer: { type: 'storage' }\r\n                },\r\n                {\r\n                    binding: 2,\r\n                    visibility: GPUShaderStage.COMPUTE,\r\n                    buffer: { type: 'storage' }\r\n                },\r\n                ...(this.local_shuffle && this.has_values ? [{\r\n                    binding: 3,\r\n                    visibility: GPUShaderStage.COMPUTE,\r\n                    buffer: { type: 'storage' }\r\n                }] : [])\r\n            ]\r\n        })\r\n\r\n        const bindGroup = this.device.createBindGroup({\r\n            layout: bindGroupLayout,\r\n            entries: [\r\n                {\r\n                    binding: 0,\r\n                    resource: { buffer: inKeys }\r\n                },\r\n                {\r\n                    binding: 1,\r\n                    resource: { buffer: this.buffers.localPrefixSum }\r\n                },\r\n                {\r\n                    binding: 2,\r\n                    resource: { buffer: this.buffers.prefixBlockSum }\r\n                },\r\n                // \"Local shuffle\" optimization needs access to the values buffer\r\n                ...(this.local_shuffle && this.has_values ? [{\r\n                    binding: 3,\r\n                    resource: { buffer: inValues }\r\n                }] : [])\r\n            ]\r\n        })\r\n\r\n        const pipelineLayout = this.device.createPipelineLayout({\r\n            bindGroupLayouts: [ bindGroupLayout ]\r\n        })\r\n\r\n        const blockSumPipeline = this.device.createComputePipeline({\r\n            label: 'radix-sort-block-sum',\r\n            layout: pipelineLayout,\r\n            compute: {\r\n                module: this.shaderModules.blockSum,\r\n                entryPoint: 'radix_sort',\r\n                constants: {\r\n                    'WORKGROUP_SIZE_X': this.workgroup_size.x,\r\n                    'WORKGROUP_SIZE_Y': this.workgroup_size.y,\r\n                    'WORKGROUP_COUNT': this.workgroup_count,\r\n                    'THREADS_PER_WORKGROUP': this.threads_per_workgroup,\r\n                    'ELEMENT_COUNT': this.count,\r\n                    'CURRENT_BIT': bit,\r\n                }\r\n            }\r\n        })\r\n\r\n        return {\r\n            pipeline: blockSumPipeline,\r\n            bindGroup\r\n        }\r\n    }\r\n\r\n    create_reorder_pipeline(inKeys, inValues, outKeys, outValues, bit) {\r\n        const bindGroupLayout = this.device.createBindGroupLayout({\r\n            label: 'radix-sort-reorder',\r\n            entries: [\r\n                {\r\n                    binding: 0,\r\n                    visibility: GPUShaderStage.COMPUTE,\r\n                    buffer: { type: 'read-only-storage' }\r\n                },\r\n                {\r\n                    binding: 1,\r\n                    visibility: GPUShaderStage.COMPUTE,\r\n                    buffer: { type: 'storage' }\r\n                },\r\n                {\r\n                    binding: 2,\r\n                    visibility: GPUShaderStage.COMPUTE,\r\n                    buffer: { type: 'read-only-storage' }\r\n                },\r\n                {\r\n                    binding: 3,\r\n                    visibility: GPUShaderStage.COMPUTE,\r\n                    buffer: { type: 'read-only-storage' }\r\n                },\r\n                ...(this.has_values ? [\r\n                    {\r\n                        binding: 4,\r\n                        visibility: GPUShaderStage.COMPUTE,\r\n                        buffer: { type: 'read-only-storage' }\r\n                    },\r\n                    {\r\n                        binding: 5,\r\n                        visibility: GPUShaderStage.COMPUTE,\r\n                        buffer: { type: 'storage' }\r\n                    }\r\n                ] : [])\r\n            ]\r\n        })\r\n\r\n        const bindGroup = this.device.createBindGroup({\r\n            layout: bindGroupLayout,\r\n            entries: [\r\n                {\r\n                    binding: 0,\r\n                    resource: { buffer: inKeys }\r\n                },\r\n                {\r\n                    binding: 1,\r\n                    resource: { buffer: outKeys }\r\n                },\r\n                {\r\n                    binding: 2,\r\n                    resource: { buffer: this.buffers.localPrefixSum }\r\n                },\r\n                {\r\n                    binding: 3,\r\n                    resource: { buffer: this.buffers.prefixBlockSum }\r\n                },\r\n                ...(this.has_values ? [\r\n                    {\r\n                        binding: 4,\r\n                        resource: { buffer: inValues }\r\n                    },\r\n                    {\r\n                        binding: 5,\r\n                        resource: { buffer: outValues }\r\n                    }\r\n                ] : [])\r\n            ]\r\n        })\r\n\r\n        const pipelineLayout = this.device.createPipelineLayout({\r\n            bindGroupLayouts: [ bindGroupLayout ]\r\n        })\r\n\r\n        const reorderPipeline = this.device.createComputePipeline({\r\n            label: 'radix-sort-reorder',\r\n            layout: pipelineLayout,\r\n            compute: {\r\n                module: this.shaderModules.reorder,\r\n                entryPoint: 'radix_sort_reorder',\r\n                constants: {\r\n                    'WORKGROUP_SIZE_X': this.workgroup_size.x,\r\n                    'WORKGROUP_SIZE_Y': this.workgroup_size.y,\r\n                    'WORKGROUP_COUNT': this.workgroup_count,\r\n                    'THREADS_PER_WORKGROUP': this.threads_per_workgroup,\r\n                    'ELEMENT_COUNT': this.count,\r\n                    'CURRENT_BIT': bit,\r\n                }\r\n            }\r\n        })\r\n\r\n        return {\r\n            pipeline: reorderPipeline,\r\n            bindGroup\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Encode all pipelines into the current pass\r\n     * \r\n     * @param {GPUComputePassEncoder} pass \r\n     */\r\n    dispatch(pass) {\r\n        if (!this.check_order) {\r\n            this.#dispatchPipelines(pass)\r\n        }\r\n        else {\r\n            this.#dispatchPipelinesIndirect(pass)\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Dispatch workgroups from CPU args\r\n     */\r\n    #dispatchPipelines(pass) {\r\n        for (let i = 0; i < this.bit_count / 2; i++) {\r\n            const { blockSumPipeline, reorderPipeline } = this.pipelines[i]\r\n            \r\n            // Compute local prefix sums and block sums\r\n            pass.setPipeline(blockSumPipeline.pipeline)\r\n            pass.setBindGroup(0, blockSumPipeline.bindGroup)\r\n            pass.dispatchWorkgroups(this.dispatchSize.x, this.dispatchSize.y, 1)\r\n\r\n            // Compute block sums prefix sum\r\n            this.kernels.prefixSum.dispatch(pass)\r\n\r\n            // Reorder keys and values\r\n            pass.setPipeline(reorderPipeline.pipeline)\r\n            pass.setBindGroup(0, reorderPipeline.bindGroup)\r\n            pass.dispatchWorkgroups(this.dispatchSize.x, this.dispatchSize.y, 1)\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Dispatch workgroups from indirect GPU buffers (used when check_order is enabled)\r\n     */\r\n    #dispatchPipelinesIndirect(pass) {\r\n        // Reset the `dispatch` and `is_sorted` buffers\r\n        this.kernels.checkSort.reset.dispatch(pass)\r\n        \r\n        for (let i = 0; i < this.bit_count / 2; i++) {\r\n            const { blockSumPipeline, reorderPipeline } = this.pipelines[i]\r\n\r\n            if (i % 2 == 0) {\r\n                // Check if the data is sorted every 2 passes\r\n                this.kernels.checkSort.fast.dispatch(pass, this.buffers.dispatchSize, this.dispatchOffsets.check_sort_fast)\r\n                this.kernels.checkSort.full.dispatch(pass, this.buffers.checkSortFullDispatchSize)\r\n            }\r\n            \r\n            // Compute local prefix sums and block sums\r\n            pass.setPipeline(blockSumPipeline.pipeline)\r\n            pass.setBindGroup(0, blockSumPipeline.bindGroup)\r\n            pass.dispatchWorkgroupsIndirect(this.buffers.dispatchSize, this.dispatchOffsets.radix_sort)\r\n\r\n            // Compute block sums prefix sum\r\n            this.kernels.prefixSum.dispatch(pass, this.buffers.dispatchSize, this.dispatchOffsets.prefix_sum)\r\n\r\n            // Reorder keys and values\r\n            pass.setPipeline(reorderPipeline.pipeline)\r\n            pass.setBindGroup(0, reorderPipeline.bindGroup)\r\n            pass.dispatchWorkgroupsIndirect(this.buffers.dispatchSize, this.dispatchOffsets.radix_sort)\r\n        }\r\n    }\r\n}\r\n\r\nexport default RadixSortKernel","/**\r\n * Radix sort with \"local shuffle and coalesced mapping\" optimization\r\n * \r\n * (see Implementation section in README for details)\r\n */\r\nconst radixSortCoalescedSource = /* wgsl */ `\r\n\r\n@group(0) @binding(0) var<storage, read_write> input: array<u32>;\r\n@group(0) @binding(1) var<storage, read_write> local_prefix_sums: array<u32>;\r\n@group(0) @binding(2) var<storage, read_write> block_sums: array<u32>;\r\n@group(0) @binding(3) var<storage, read_write> values: array<u32>;\r\n\r\noverride WORKGROUP_COUNT: u32;\r\noverride THREADS_PER_WORKGROUP: u32;\r\noverride WORKGROUP_SIZE_X: u32;\r\noverride WORKGROUP_SIZE_Y: u32;\r\noverride CURRENT_BIT: u32;\r\noverride ELEMENT_COUNT: u32;\r\n\r\nvar<workgroup> s_prefix_sum: array<u32, 2 * (THREADS_PER_WORKGROUP + 1)>;\r\nvar<workgroup> s_prefix_sum_scan: array<u32, 4>;\r\n\r\n@compute @workgroup_size(WORKGROUP_SIZE_X, WORKGROUP_SIZE_Y, 1)\r\nfn radix_sort(\r\n    @builtin(workgroup_id) w_id: vec3<u32>,\r\n    @builtin(num_workgroups) w_dim: vec3<u32>,\r\n    @builtin(local_invocation_index) TID: u32, // Local thread ID\r\n) {\r\n    let WORKGROUP_ID = w_id.x + w_id.y * w_dim.x;\r\n    let WID = WORKGROUP_ID * THREADS_PER_WORKGROUP;\r\n    let GID = WID + TID; // Global thread ID\r\n\r\n    // Extract 2 bits from the input\r\n    var elm: u32 = 0;\r\n    var val: u32 = 0;\r\n    if (GID < ELEMENT_COUNT) {\r\n        elm = input[GID];\r\n        val = values[GID];\r\n    }\r\n    let extract_bits: u32 = (elm >> CURRENT_BIT) & 0x3;\r\n\r\n    var bit_prefix_sums = array<u32, 4>(0, 0, 0, 0);\r\n\r\n    // If the workgroup is inactive, prevent block_sums buffer update\r\n    var LAST_THREAD: u32 = 0xffffffff; \r\n\r\n    if (WORKGROUP_ID < WORKGROUP_COUNT) {\r\n        // Otherwise store the index of the last active thread in the workgroup\r\n        LAST_THREAD = min(THREADS_PER_WORKGROUP, ELEMENT_COUNT - WID) - 1;\r\n    }\r\n\r\n    // Initialize parameters for double-buffering\r\n    let TPW = THREADS_PER_WORKGROUP + 1;\r\n    var swapOffset: u32 = 0;\r\n    var inOffset:  u32 = TID;\r\n    var outOffset: u32 = TID + TPW;\r\n\r\n    // 4-way prefix sum\r\n    for (var b: u32 = 0; b < 4; b++) {\r\n        // Initialize local prefix with bitmask\r\n        let bitmask = select(0u, 1u, extract_bits == b);\r\n        s_prefix_sum[inOffset + 1] = bitmask;\r\n        workgroupBarrier();\r\n\r\n        var prefix_sum: u32 = 0;\r\n\r\n        // Prefix sum\r\n        for (var offset: u32 = 1; offset < THREADS_PER_WORKGROUP; offset *= 2) {\r\n            if (TID >= offset) {\r\n                prefix_sum = s_prefix_sum[inOffset] + s_prefix_sum[inOffset - offset];\r\n            } else {\r\n                prefix_sum = s_prefix_sum[inOffset];\r\n            }\r\n\r\n            s_prefix_sum[outOffset] = prefix_sum;\r\n\r\n            // Swap buffers\r\n            outOffset = inOffset;\r\n            swapOffset = TPW - swapOffset;\r\n            inOffset = TID + swapOffset;\r\n            \r\n            workgroupBarrier();\r\n        }\r\n\r\n        // Store prefix sum for current bit\r\n        bit_prefix_sums[b] = prefix_sum;\r\n\r\n        if (TID == LAST_THREAD) {\r\n            // Store block sum to global memory\r\n            let total_sum: u32 = prefix_sum + bitmask;\r\n            block_sums[b * WORKGROUP_COUNT + WORKGROUP_ID] = total_sum;\r\n        }\r\n\r\n        // Swap buffers\r\n        outOffset = inOffset;\r\n        swapOffset = TPW - swapOffset;\r\n        inOffset = TID + swapOffset;\r\n    }\r\n\r\n    let prefix_sum = bit_prefix_sums[extract_bits];   \r\n\r\n    // Scan bit prefix sums\r\n    if (TID == LAST_THREAD) {\r\n        var sum: u32 = 0;\r\n        bit_prefix_sums[extract_bits] += 1;\r\n        for (var i: u32 = 0; i < 4; i++) {\r\n            s_prefix_sum_scan[i] = sum;\r\n            sum += bit_prefix_sums[i];\r\n        }\r\n    }\r\n    workgroupBarrier();\r\n\r\n    if (GID < ELEMENT_COUNT) {\r\n        // Compute new position\r\n        let new_pos: u32 = prefix_sum + s_prefix_sum_scan[extract_bits];\r\n\r\n        // Shuffle elements locally\r\n        input[WID + new_pos] = elm;\r\n        values[WID + new_pos] = val;\r\n        local_prefix_sums[WID + new_pos] = prefix_sum;\r\n    }\r\n}`\r\n\r\nexport default radixSortCoalescedSource;","const radixSortSource = /* wgsl */ `\r\n\r\n@group(0) @binding(0) var<storage, read> input: array<u32>;\r\n@group(0) @binding(1) var<storage, read_write> local_prefix_sums: array<u32>;\r\n@group(0) @binding(2) var<storage, read_write> block_sums: array<u32>;\r\n\r\noverride WORKGROUP_COUNT: u32;\r\noverride THREADS_PER_WORKGROUP: u32;\r\noverride WORKGROUP_SIZE_X: u32;\r\noverride WORKGROUP_SIZE_Y: u32;\r\noverride CURRENT_BIT: u32;\r\noverride ELEMENT_COUNT: u32;\r\n\r\nvar<workgroup> s_prefix_sum: array<u32, 2 * (THREADS_PER_WORKGROUP + 1)>;\r\n\r\n@compute @workgroup_size(WORKGROUP_SIZE_X, WORKGROUP_SIZE_Y, 1)\r\nfn radix_sort(\r\n    @builtin(workgroup_id) w_id: vec3<u32>,\r\n    @builtin(num_workgroups) w_dim: vec3<u32>,\r\n    @builtin(local_invocation_index) TID: u32, // Local thread ID\r\n) {\r\n    let WORKGROUP_ID = w_id.x + w_id.y * w_dim.x;\r\n    let WID = WORKGROUP_ID * THREADS_PER_WORKGROUP;\r\n    let GID = WID + TID; // Global thread ID\r\n\r\n    // Extract 2 bits from the input\r\n    let elm = select(input[GID], 0, GID >= ELEMENT_COUNT);\r\n    let extract_bits: u32 = (elm >> CURRENT_BIT) & 0x3;\r\n\r\n    var bit_prefix_sums = array<u32, 4>(0, 0, 0, 0);\r\n\r\n    // If the workgroup is inactive, prevent block_sums buffer update\r\n    var LAST_THREAD: u32 = 0xffffffff; \r\n\r\n    if (WORKGROUP_ID < WORKGROUP_COUNT) {\r\n        // Otherwise store the index of the last active thread in the workgroup\r\n        LAST_THREAD = min(THREADS_PER_WORKGROUP, ELEMENT_COUNT - WID) - 1;\r\n    }\r\n\r\n    // Initialize parameters for double-buffering\r\n    let TPW = THREADS_PER_WORKGROUP + 1;\r\n    var swapOffset: u32 = 0;\r\n    var inOffset:  u32 = TID;\r\n    var outOffset: u32 = TID + TPW;\r\n\r\n    // 4-way prefix sum\r\n    for (var b: u32 = 0; b < 4; b++) {\r\n        // Initialize local prefix with bitmask\r\n        let bitmask = select(0u, 1u, extract_bits == b);\r\n        s_prefix_sum[inOffset + 1] = bitmask;\r\n        workgroupBarrier();\r\n\r\n        var prefix_sum: u32 = 0;\r\n\r\n        // Prefix sum\r\n        for (var offset: u32 = 1; offset < THREADS_PER_WORKGROUP; offset *= 2) {\r\n            if (TID >= offset) {\r\n                prefix_sum = s_prefix_sum[inOffset] + s_prefix_sum[inOffset - offset];\r\n            } else {\r\n                prefix_sum = s_prefix_sum[inOffset];\r\n            }\r\n\r\n            s_prefix_sum[outOffset] = prefix_sum;\r\n            \r\n            // Swap buffers\r\n            outOffset = inOffset;\r\n            swapOffset = TPW - swapOffset;\r\n            inOffset = TID + swapOffset;\r\n            \r\n            workgroupBarrier();\r\n        }\r\n\r\n        // Store prefix sum for current bit\r\n        bit_prefix_sums[b] = prefix_sum;\r\n\r\n        if (TID == LAST_THREAD) {\r\n            // Store block sum to global memory\r\n            let total_sum: u32 = prefix_sum + bitmask;\r\n            block_sums[b * WORKGROUP_COUNT + WORKGROUP_ID] = total_sum;\r\n        }\r\n\r\n        // Swap buffers\r\n        outOffset = inOffset;\r\n        swapOffset = TPW - swapOffset;\r\n        inOffset = TID + swapOffset;\r\n    }\r\n\r\n    if (GID < ELEMENT_COUNT) {\r\n        // Store local prefix sum to global memory\r\n        local_prefix_sums[GID] = bit_prefix_sums[extract_bits];\r\n    }\r\n}`\r\n\r\nexport default radixSortSource;"],"names":["find_optimal_dispatch_size","device","workgroup_count","dispatchSize","x","y","limits","maxComputeWorkgroupsPerDimension","Math","floor","sqrt","ceil","create_buffer_from_data","_ref","label","data","_ref$usage","usage","dispatchSizes","createBuffer","size","length","mappedAtCreation","Uint32Array","getMappedRange","set","unmap","PrefixSumKernel","_createClass","count","_ref$workgroup_size","workgroup_size","_ref$avoid_bank_confl","avoid_bank_conflicts","_classCallCheck","this","threads_per_workgroup","items_per_workgroup","log2","Error","concat","pipelines","shaderModule","createShaderModule","code","create_pass_recursive","key","value","blockSumBuffer","GPUBufferUsage","STORAGE","COPY_SRC","COPY_DST","bindGroupLayout","createBindGroupLayout","entries","binding","visibility","GPUShaderStage","COMPUTE","buffer","type","bindGroup","createBindGroup","layout","resource","pipelineLayout","createPipelineLayout","bindGroupLayouts","scanPipeline","createComputePipeline","compute","module","entryPoint","constants","WORKGROUP_SIZE_X","WORKGROUP_SIZE_Y","THREADS_PER_WORKGROUP","ITEMS_PER_WORKGROUP","ELEMENT_COUNT","push","pipeline","blockSumPipeline","flatMap","p","pass","dispatchSizeBuffer","offset","arguments","undefined","i","_this$pipelines$i","setPipeline","setBindGroup","dispatchWorkgroups","dispatchWorkgroupsIndirect","radixSortReorderSource","checkSortSource","isLastPass","kernelMode","first_pass_load_data","last_pass","write_reduction_result","last_pass_full","last_pass_fast","CheckSortKernel","result","original","is_sorted","_ref$start","start","_ref$mode","mode","buffers","outputs","create_passes_recursive","passIndex","isFirstPass","outputBuffer","_toConsumableArray","element_count","start_element","checkSortPipeline","_objectSpread","START_ELEMENT","dispatchIndirect","item_count","sizes","target_workgroup_count","_RadixSortKernel_brand","WeakSet","RadixSortKernel","keys","values","_ref$bit_count","bit_count","_ref$check_order","check_order","_ref$local_shuffle","local_shuffle","_classPrivateMethodInitSpec","Number","isInteger","prefix_block_workgroup_count","has_values","shaderModules","kernels","create_shader_modules","create_pipelines","remove_values","source","split","filter","line","toLowerCase","includes","join","blockSumSource","blockSum","reorder","reorderSource","create_prefix_sum_kernel","dispatchData","calculate_dispatch_sizes","create_buffers","create_check_sort_kernels","bit","even","inKeys","tmpKeys","inValues","tmpValues","outKeys","outValues","create_block_sum_pipeline","reorderPipeline","create_reorder_pipeline","prefixBlockSumBuffer","prefixSumKernel","prefixSum","prefixBlockSum","prefixSumDispatchSize","get_dispatch_chain","check_sort_fast_count","min","check_sort_full_count","start_full","dispatchSizesFast","find_optimal_dispatch_chain","dispatchSizesFull","initialDispatch","slice","dispatchOffsets","radix_sort","check_sort_fast","prefix_sum","tmpKeysBuffer","tmpValuesBuffer","localPrefixSumBuffer","localPrefixSum","dispatchBuffer","INDIRECT","originalDispatchBuffer","checkSortFullDispatchBuffer","checkSortFullOriginalDispatchBuffer","isSortedBuffer","originalDispatchSize","checkSortFullDispatchSize","originalCheckSortFullDispatchSize","isSorted","checkSortPartitionData","checkSortFull","checkSortFast","initialDispatchElementCount","console","warn","checkSortReset","checkSort","reset","fast","full","WORKGROUP_COUNT","CURRENT_BIT","_assertClassBrand","_dispatchPipelinesIndirect","call","_dispatchPipelines","dispatch","_this$pipelines$i2"],"mappings":"8mFAOA,SAASA,EAA2BC,EAAQC,GACxC,IAAMC,EAAe,CACjBC,EAAGF,EACHG,EAAG,GAGP,GAAIH,EAAkBD,EAAOK,OAAOC,iCAAkC,CAClE,IAAMH,EAAII,KAAKC,MAAMD,KAAKE,KAAKR,IACzBG,EAAIG,KAAKG,KAAKT,EAAkBE,GAEtCD,EAAaC,EAAIA,EACjBD,EAAaE,EAAIA,CACrB,CAEA,OAAOF,CACX,CAEA,SAASS,EAAuBC,GAAmC,IAAjCZ,EAAMY,EAANZ,OAAQa,EAAKD,EAALC,MAAOC,EAAIF,EAAJE,KAAIC,EAAAH,EAAEI,MAAAA,OAAQ,IAAHD,EAAG,EAACA,EACtDE,EAAgBjB,EAAOkB,aAAa,CACtCL,MAAOA,EACPG,MAAOA,EACPG,KAAoB,EAAdL,EAAKM,OACXC,kBAAkB,IAOtB,OAJqB,IAAIC,YAAYL,EAAcM,kBACtCC,IAAIV,GACjBG,EAAcQ,QAEPR,CACX,CCjCMS,IAAAA,EAAe,WAoChB,OAAAC,GAvBD,SAAAD,EAAAd,GAMG,IALCZ,EAAMY,EAANZ,OACAc,EAAIF,EAAJE,KACAc,EAAKhB,EAALgB,MAAKC,EAAAjB,EACLkB,eAAAA,OAAiB,IAAHD,EAAG,CAAE1B,EAAG,GAAIC,EAAG,IAAIyB,EAAAE,EAAAnB,EACjCoB,qBAAAA,OAAuB,IAAHD,GAAQA,EAO5B,GAP4BE,OAAAP,GAE5BQ,KAAKlC,OAASA,EACdkC,KAAKJ,eAAiBA,EACtBI,KAAKC,sBAAwBL,EAAe3B,EAAI2B,EAAe1B,EAC/D8B,KAAKE,oBAAsB,EAAIF,KAAKC,sBAEhC5B,KAAK8B,KAAKH,KAAKC,uBAAyB,GAAM,EAC9C,MAAM,IAAIG,MAAKC,yEAAAA,OAA0EL,KAAKC,sBAAqB,MAEvHD,KAAKM,UAAY,GAEjBN,KAAKO,aAAeP,KAAKlC,OAAO0C,mBAAmB,CAC/C7B,MAAO,aACP8B,KAAMX,EC2FhB,giHCrBA,q/FFnEME,KAAKU,sBAAsB9B,EAAMc,EACrC,GAAC,CAAA,CAAAiB,IAAA,wBAAAC,MAED,SAAsBhC,EAAMc,GAExB,IAAM3B,EAAkBM,KAAKG,KAAKkB,EAAQM,KAAKE,qBACzClC,EAAeH,EAA2BmC,KAAKlC,OAAQC,GAGvD8C,EAAiBb,KAAKlC,OAAOkB,aAAa,CAC5CL,MAAO,uBACPM,KAAwB,EAAlBlB,EACNe,MAAOgC,eAAeC,QAAUD,eAAeE,SAAWF,eAAeG,WAIvEC,EAAkBlB,KAAKlC,OAAOqD,sBAAsB,CACtDC,QAAS,CACL,CACIC,QAAS,EACTC,WAAYC,eAAeC,QAC3BC,OAAQ,CAAEC,KAAM,YAEpB,CACIL,QAAS,EACTC,WAAYC,eAAeC,QAC3BC,OAAQ,CAAEC,KAAM,eAKtBC,EAAY3B,KAAKlC,OAAO8D,gBAAgB,CAC1CjD,MAAO,wBACPkD,OAAQX,EACRE,QAAS,CACL,CACIC,QAAS,EACTS,SAAU,CAAEL,OAAQ7C,IAExB,CACIyC,QAAS,EACTS,SAAU,CAAEL,OAAQZ,OAK1BkB,EAAiB/B,KAAKlC,OAAOkE,qBAAqB,CACpDC,iBAAkB,CAAEf,KAIlBgB,EAAelC,KAAKlC,OAAOqE,sBAAsB,CACnDxD,MAAO,2BACPkD,OAAQE,EACRK,QAAS,CACLC,OAAQrC,KAAKO,aACb+B,WAAY,mBACZC,UAAW,CACPC,iBAAoBxC,KAAKJ,eAAe3B,EACxCwE,iBAAoBzC,KAAKJ,eAAe1B,EACxCwE,sBAAyB1C,KAAKC,sBAC9B0C,oBAAuB3C,KAAKE,oBAC5B0C,cAAiBlD,MAO7B,GAFAM,KAAKM,UAAUuC,KAAK,CAAEC,SAAUZ,EAAcP,UAAAA,EAAW3D,aAAAA,IAErDD,EAAkB,EAAG,CAErBiC,KAAKU,sBAAsBG,EAAgB9C,GAG3C,IAAMgF,EAAmB/C,KAAKlC,OAAOqE,sBAAsB,CACvDxD,MAAO,gCACPkD,OAAQE,EACRK,QAAS,CACLC,OAAQrC,KAAKO,aACb+B,WAAY,iBACZC,UAAW,CACPC,iBAAoBxC,KAAKJ,eAAe3B,EACxCwE,iBAAoBzC,KAAKJ,eAAe1B,EACxCwE,sBAAyB1C,KAAKC,sBAC9B2C,cAAiBlD,MAK7BM,KAAKM,UAAUuC,KAAK,CAAEC,SAAUC,EAAkBpB,UAAAA,EAAW3D,aAAAA,GACjE,CACJ,GAAC,CAAA2C,IAAA,qBAAAC,MAED,WACI,OAAOZ,KAAKM,UAAU0C,SAAQ,SAAAC,GAAC,MAAI,CAAEA,EAAEjF,aAAaC,EAAGgF,EAAEjF,aAAaE,EAAG,KAC7E,GAEA,CAAAyC,IAAA,WAAAC,MAQA,SAASsC,EAAMC,GACX,IAD2C,IAAZC,EAAMC,UAAAnE,OAAA,QAAAoE,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAC/BE,EAAI,EAAGA,EAAIvD,KAAKM,UAAUpB,OAAQqE,IAAK,CAC5C,IAAAC,EAA8CxD,KAAKM,UAAUiD,GAArDT,EAAQU,EAARV,SAAUnB,EAAS6B,EAAT7B,UAAW3D,EAAYwF,EAAZxF,aAE7BkF,EAAKO,YAAYX,GACjBI,EAAKQ,aAAa,EAAG/B,GAEK,MAAtBwB,EACAD,EAAKS,mBAAmB3F,EAAaC,EAAGD,EAAaE,EAAG,GAExDgF,EAAKU,2BAA2BT,EAAoBC,EAAa,EAAJG,EAAQ,EAC7E,CACJ,IAAC,CAxJgB,GGJfM,EA0CJ,y9CC1CIC,EAAkB,WAAH,IAAyBC,EAAUV,UAAAnE,OAAA,QAAAoE,IAAAD,UAAA,IAAAA,UAAA,GAAUW,EAAUX,UAAAnE,OAAA,QAAAoE,IAAAD,UAAA,GAAAA,UAAA,GAAG,OAAM,o5CAAKhD,OAAtDgD,UAAAnE,OAAA,QAAAoE,IAAAD,UAAA,IAAAA,UAAA,GA8CfY,EAAuB,6DAA4D,8SAAA5D,OAYjG0D,EAAaG,EAAUF,GAAcG,EAAsB,MAAA,EAG5DA,EAIL,4EAEKF,EAWL,2aAEKC,EAAY,SAACF,GAAU,MAAK,2KAAA3D,OAQd,QAAd2D,EAAuBI,EAAiBC,EAAc,KAAA,EAItDA,EAEL,yGAGKD,EAML,+JCpGKE,EAAe,WA6CjB,OAAA7E,GA/BA,SAAA6E,EAAA5F,GAUG,IATCZ,EAAMY,EAANZ,OACAc,EAAIF,EAAJE,KACA2F,EAAM7F,EAAN6F,OACAC,EAAQ9F,EAAR8F,SACAC,EAAS/F,EAAT+F,UACA/E,EAAKhB,EAALgB,MAAKgF,EAAAhG,EACLiG,MAAAA,OAAQ,IAAHD,EAAG,EAACA,EAAAE,EAAAlG,EACTmG,KAAAA,OAAO,IAAHD,EAAG,OAAMA,EAAAjF,EAAAjB,EACbkB,eAAAA,OAAiB,IAAHD,EAAG,CAAE1B,EAAG,GAAIC,EAAG,IAAIyB,EAAAI,OAAAuE,GAEjCtE,KAAKlC,OAASA,EACdkC,KAAKN,MAAQA,EACbM,KAAK2E,MAAQA,EACb3E,KAAK6E,KAAOA,EACZ7E,KAAKJ,eAAiBA,EACtBI,KAAKC,sBAAwBL,EAAe3B,EAAI2B,EAAe1B,EAE/D8B,KAAKM,UAAY,GAEjBN,KAAK8E,QAAU,CACXlG,KAAAA,EACA2F,OAAAA,EACAC,SAAAA,EACAC,UAAAA,EACAM,QAAS,IAGb/E,KAAKgF,wBAAwBpG,EAAMc,EACvC,GAEA,CAAA,CAAAiB,IAAA,0BAAAC,MAmBA,SAAwBa,EAAQ/B,GAAsB,IAAfuF,EAAS5B,UAAAnE,OAAA,QAAAoE,IAAAD,UAAA,GAAAA,UAAA,GAAG,EACzCtF,EAAkBM,KAAKG,KAAKkB,EAAQM,KAAKC,uBAEzCiF,EAA4B,IAAdD,EACdlB,EAAahG,GAAmB,EAEhCY,EAAK0B,cAAAA,OAAiBL,KAAK6E,KAAIxE,KAAAA,OAAI4E,GAEnCE,EAAepB,EAAa/D,KAAK8E,QAAQP,OAASvE,KAAKlC,OAAOkB,aAAa,CAC7EL,MAAOA,EACPM,KAAwB,EAAlBlB,EACNe,MAAOgC,eAAeC,QAAUD,eAAeE,SAAWF,eAAeG,WAGvEC,EAAkBlB,KAAKlC,OAAOqD,sBAAsB,CACtDC,QACI,CAAA,CACIC,QAAS,EACTC,WAAYC,eAAeC,QAC3BC,OAAQ,CAAEC,KAAM,sBAEpB,CACIL,QAAS,EACTC,WAAYC,eAAeC,QAC3BC,OAAQ,CAAEC,KAAM,aACnBrB,OAAA+E,EAEGrB,EAAa,CAAC,CACd1C,QAAS,EACTC,WAAYC,eAAeC,QAC3BC,OAAQ,CAAEC,KAAM,sBACjB,CACCL,QAAS,EACTC,WAAYC,eAAeC,QAC3BC,OAAQ,CAAEC,KAAM,aACf,OAIPC,EAAY3B,KAAKlC,OAAO8D,gBAAgB,CAC1CC,OAAQX,EACRE,QACI,CAAA,CACIC,QAAS,EACTS,SAAU,CAAEL,OAAQA,IAExB,CACIJ,QAAS,EACTS,SAAU,CAAEL,OAAQ0D,KACvB9E,OAAA+E,EAEGrB,EAAa,CAAC,CACd1C,QAAS,EACTS,SAAU,CAAEL,OAAQzB,KAAK8E,QAAQN,WAClC,CACCnD,QAAS,EACTS,SAAU,CAAEL,OAAQzB,KAAK8E,QAAQL,aAChC,OAIP1C,EAAiB/B,KAAKlC,OAAOkE,qBAAqB,CACpDC,iBAAkB,CAACf,KAGjBmE,EAAgBH,EAAclF,KAAK2E,MAAQjF,EAAQA,EACnD4F,EAAgBJ,EAAclF,KAAK2E,MAAQ,EAE3CY,EAAoBvF,KAAKlC,OAAOqE,sBAAsB,CACxDN,OAAQE,EACRK,QAAS,CACLC,OAAQrC,KAAKlC,OAAO0C,mBAAmB,CACnC7B,MAAOA,EACP8B,KAAMqD,EAAgBoB,EAAanB,EAAY/D,KAAK6E,QAExDvC,WAAyB,SAAbtC,KAAK6E,KAAkB,QAAU,aAC7CtC,UAASiD,EAAA,CACL5C,cAAiByC,EACjB7C,iBAAoBxC,KAAKJ,eAAe3B,EACxCwE,iBAAoBzC,KAAKJ,eAAe1B,GACvB,SAAb8B,KAAK6E,MAAmB,CACxBnC,sBAAyB1C,KAAKC,sBAC9BwF,cAAiBH,OAMjCtF,KAAK8E,QAAQC,QAAQlC,KAAKsC,GAC1BnF,KAAKM,UAAUuC,KAAK,CAAEC,SAAUyC,EAAmB5D,UAAAA,IAE9CoC,GACD/D,KAAKgF,wBAAwBG,EAAcpH,EAAiBkH,EAAY,EAEhF,GAAC,CAAAtE,IAAA,WAAAC,MAED,SAASsC,EAAMlF,GACX,IADqC,IAAZoF,EAAMC,UAAAnE,OAAA,QAAAoE,IAAAD,UAAA,GAAAA,UAAA,GAAG,EACzBE,EAAI,EAAGA,EAAIvD,KAAKM,UAAUpB,OAAQqE,IAAK,CAC5C,IAAAC,EAAgCxD,KAAKM,UAAUiD,GAAvCT,EAAQU,EAARV,SAAUnB,EAAS6B,EAAT7B,UAEZ+D,EAAgC,SAAb1F,KAAK6E,OAAiC,QAAb7E,KAAK6E,MAAkBtB,EAAIvD,KAAKM,UAAUpB,OAAS,GAErGgE,EAAKO,YAAYX,GACjBI,EAAKQ,aAAa,EAAG/B,GAEjB+D,EACAxC,EAAKU,2BAA2B5F,EAAcoF,EAAa,EAAJG,EAAQ,GAG/DL,EAAKS,mBAAmB,EAAG,EAAG,EACtC,CACJ,IAAC,CAAA,CAAAhD,IAAA,8BAAAC,MAjID,SAAmC9C,EAAQ6H,EAAY/F,GACnD,IAAMK,EAAwBL,EAAe3B,EAAI2B,EAAe1B,EAC1D0H,EAAQ,GAEd,EAAG,CAEC,IAAMC,EAAyBxH,KAAKG,KAAKmH,EAAa1F,GAGhDjC,EAAeH,EAA2BC,EAAQ+H,GAExDD,EAAM/C,KAAK7E,EAAaC,EAAGD,EAAaE,EAAG,GAC3CyH,EAAaE,QACRF,EAAa,GAEtB,OAAOC,CACX,IAAC,CA9DgB,GCEwDE,MAAAC,QAEvEC,EAAe,WAgEhB,OAAAvG,GA9CD,SAAAuG,IAUQ,IAAAtH,EAAA2E,UAAAnE,OAAA,QAAAoE,IAAAD,UAAA,GAAAA,UAAA,GAAJ,CAAE,EATFvF,EAAMY,EAANZ,OACAmI,EAAIvH,EAAJuH,KACAC,EAAMxH,EAANwH,OACAxG,EAAKhB,EAALgB,MAAKyG,EAAAzH,EACL0H,UAAAA,OAAY,IAAHD,EAAG,GAAEA,EAAAxG,EAAAjB,EACdkB,eAAAA,OAAiB,IAAHD,EAAG,CAAE1B,EAAG,GAAIC,EAAG,IAAIyB,EAAA0G,EAAA3H,EACjC4H,YAAAA,OAAc,IAAHD,GAAQA,EAAAE,EAAA7H,EACnB8H,cAAAA,OAAgB,IAAHD,GAAQA,EAAA1G,EAAAnB,EACrBoB,qBAAAA,OAAuB,IAAHD,GAAQA,EAE5B,GAF4BE,OAAAiG,GA4dhCS,OAAAX,GA1dkB,MAAVhI,EAAgB,MAAM,IAAIsC,MAAM,sBACpC,GAAY,MAAR6F,EAAc,MAAM,IAAI7F,MAAM,2BAClC,IAAKsG,OAAOC,UAAUjH,IAAUA,GAAS,EAAG,MAAM,IAAIU,MAAM,2BAC5D,IAAKsG,OAAOC,UAAUP,IAAcA,GAAa,GAAKA,EAAY,GAAI,MAAM,IAAIhG,sCAAKC,OAAiC+F,IACtH,IAAKM,OAAOC,UAAU/G,EAAe3B,KAAOyI,OAAOC,UAAU/G,EAAe1B,GAAI,MAAM,IAAIkC,MAAM,oCAChG,GAAIgG,EAAY,GAAK,EAAG,MAAM,IAAIhG,MAAM,qCAExCJ,KAAKlC,OAASA,EACdkC,KAAKN,MAAQA,EACbM,KAAKoG,UAAYA,EACjBpG,KAAKJ,eAAiBA,EACtBI,KAAKsG,YAAcA,EACnBtG,KAAKwG,cAAgBA,EACrBxG,KAAKF,qBAAuBA,EAE5BE,KAAKC,sBAAwBL,EAAe3B,EAAI2B,EAAe1B,EAC/D8B,KAAKjC,gBAAkBM,KAAKG,KAAKkB,EAAQM,KAAKC,uBAC9CD,KAAK4G,6BAA+B,EAAI5G,KAAKjC,gBAE7CiC,KAAK6G,WAAwB,MAAVX,EAEnBlG,KAAKhC,aAAe,GACpBgC,KAAK8G,cAAgB,GACrB9G,KAAK+G,QAAU,GACf/G,KAAKM,UAAY,GACjBN,KAAK8E,QAAU,CACXmB,KAAMA,EACNC,OAAQA,GAIZlG,KAAKgH,wBAGLhH,KAAKiH,kBACT,GAAC,CAAA,CAAAtG,IAAA,wBAAAC,MAED,WAEI,IAAMsG,EAAgB,SAACC,GACnB,OAAOA,EAAOC,MAAM,MACNC,QAAO,SAAAC,GAAI,OAAKA,EAAKC,cAAcC,SAAS,SAAS,IACrDC,KAAK,OAGjBC,EAAiB1H,KAAKwG,cCwClC,qvHC9BA,6iGFRMxG,KAAK8G,cAAgB,CACjBa,SAAU3H,KAAKlC,OAAO0C,mBAAmB,CACrC7B,MAAO,uBACP8B,KAAMT,KAAK6G,WAAaa,EAAiBR,EAAcQ,KAE3DE,QAAS5H,KAAKlC,OAAO0C,mBAAmB,CACpC7B,MAAO,qBACP8B,KAAMT,KAAK6G,WAAagB,EAAgBX,EAAcW,KAGlE,GAAC,CAAAlH,IAAA,mBAAAC,MAED,WAEIZ,KAAK8H,2BAGL,IAAMC,EAAe/H,KAAKgI,2BAG1BhI,KAAKiI,eAAeF,GAGpB/H,KAAKkI,0BAA0BH,GAG/B,IAAK,IAAII,EAAM,EAAGA,EAAMnI,KAAKoG,UAAW+B,GAAO,EAAG,CAE9C,IAAMC,EAAaD,EAAM,GAAK,EACxBE,EAAYD,EAAOpI,KAAK8E,QAAQmB,KAAOjG,KAAK8E,QAAQwD,QACpDC,EAAYH,EAAOpI,KAAK8E,QAAQoB,OAASlG,KAAK8E,QAAQ0D,UACtDC,EAAYL,EAAOpI,KAAK8E,QAAQwD,QAAUtI,KAAK8E,QAAQmB,KACvDyC,EAAYN,EAAOpI,KAAK8E,QAAQ0D,UAAYxI,KAAK8E,QAAQoB,OAGzDnD,EAAmB/C,KAAK2I,0BAA0BN,EAAQE,EAAUJ,GAGpES,EAAkB5I,KAAK6I,wBAAwBR,EAAQE,EAAUE,EAASC,EAAWP,GAE3FnI,KAAKM,UAAUuC,KAAK,CAAEE,iBAAAA,EAAkB6F,gBAAAA,GAC5C,CACJ,GAAC,CAAAjI,IAAA,2BAAAC,MAED,WAEI,IAAMkI,EAAuB9I,KAAKlC,OAAOkB,aAAa,CAClDL,MAAO,8BACPM,KAA0C,EAApCe,KAAK4G,6BACX9H,MAAOgC,eAAeC,QAAUD,eAAeE,SAAWF,eAAeG,WAIvE8H,EAAkB,IAAIvJ,EAAgB,CACxC1B,OAAQkC,KAAKlC,OACbc,KAAMkK,EACNpJ,MAAOM,KAAK4G,6BACZhH,eAAgBI,KAAKJ,eACrBE,qBAAsBE,KAAKF,uBAG/BE,KAAK+G,QAAQiC,UAAYD,EACzB/I,KAAK8E,QAAQmE,eAAiBH,CAClC,GAAC,CAAAnI,IAAA,2BAAAC,MAED,WAEI,IAAM5C,EAAeH,EAA2BmC,KAAKlC,OAAQkC,KAAKjC,iBAG5DmL,EAAwBlJ,KAAK+G,QAAQiC,UAAUG,qBAG/CC,EAAwB/K,KAAKgL,IAAIrJ,KAAKN,MAAoC,EAA7BM,KAAKC,uBAClDqJ,EAAwBtJ,KAAKN,MAAQ0J,EACrCG,EAAaH,EAAwB,EAGrCI,EAAoBlF,EAAgBmF,4BAA4BzJ,KAAKlC,OAAQsL,EAAuBpJ,KAAKJ,gBACzG8J,EAAoBpF,EAAgBmF,4BAA4BzJ,KAAKlC,OAAQwL,EAAuBtJ,KAAKJ,gBAGzG+J,EAAe,CACjB3L,EAAaC,EAAGD,EAAaE,EAAG,GAACmC,OAAA+E,EAC9BoE,EAAkBI,MAAM,EAAG,IAAExE,EAC7B8D,IAaP,OATAlJ,KAAK6J,gBAAkB,CACnBC,WAAY,EACZC,gBAAiB,GACjBC,WAAY,IAGhBhK,KAAKhC,aAAeA,EACpBgC,KAAK2J,gBAAkBA,EAEhB,CACHA,gBAAAA,EACAD,kBAAAA,EACAN,sBAAAA,EACAE,sBAAAA,EACAC,WAAAA,EAER,GAAC,CAAA5I,IAAA,iBAAAC,MAED,SAAemH,GAEX,IAAMkC,EAAgBjK,KAAKlC,OAAOkB,aAAa,CAC3CL,MAAO,sBACPM,KAAmB,EAAbe,KAAKN,MACXZ,MAAOgC,eAAeC,QAAUD,eAAeE,SAAWF,eAAeG,WAEvEiJ,EAAmBlK,KAAK6G,WAAoB7G,KAAKlC,OAAOkB,aAAa,CACvEL,MAAO,wBACPM,KAAmB,EAAbe,KAAKN,MACXZ,MAAOgC,eAAeC,QAAUD,eAAeE,SAAWF,eAAeG,WAHlC,KAOrCkJ,EAAuBnK,KAAKlC,OAAOkB,aAAa,CAClDL,MAAO,8BACPM,KAAmB,EAAbe,KAAKN,MACXZ,MAAOgC,eAAeC,QAAUD,eAAeE,SAAWF,eAAeG,WAQ7E,GALAjB,KAAK8E,QAAQwD,QAAU2B,EACvBjK,KAAK8E,QAAQ0D,UAAY0B,EACzBlK,KAAK8E,QAAQsF,eAAiBD,EAGzBnK,KAAKsG,YAAV,CAKA,IAAM+D,EAAiB5L,EAAwB,CAC3CX,OAAQkC,KAAKlC,OACba,MAAO,2BACPC,KAAMmJ,EAAa4B,gBACnB7K,MAAOgC,eAAeC,QAAUD,eAAeE,SAAWF,eAAewJ,WAEvEC,EAAyB9L,EAAwB,CACnDX,OAAQkC,KAAKlC,OACba,MAAO,oCACPC,KAAMmJ,EAAa4B,gBACnB7K,MAAOgC,eAAeC,QAAUD,eAAeE,WAI7CwJ,EAA8B/L,EAAwB,CACxDE,MAAO,gCACPb,OAAQkC,KAAKlC,OACbc,KAAMmJ,EAAa2B,kBACnB5K,MAAOgC,eAAeC,QAAUD,eAAeE,SAAWF,eAAewJ,WAEvEG,EAAsChM,EAAwB,CAChEE,MAAO,yCACPb,OAAQkC,KAAKlC,OACbc,KAAMmJ,EAAa2B,kBACnB5K,MAAOgC,eAAeC,QAAUD,eAAeE,WAI7C0J,EAAiBjM,EAAwB,CAC3CE,MAAO,YACPb,OAAQkC,KAAKlC,OACbc,KAAM,IAAIQ,YAAY,CAAC,IACvBN,MAAOgC,eAAeC,QAAUD,eAAeE,SAAWF,eAAeG,WAG7EjB,KAAK8E,QAAQ9G,aAAeqM,EAC5BrK,KAAK8E,QAAQ6F,qBAAuBJ,EACpCvK,KAAK8E,QAAQ8F,0BAA4BJ,EACzCxK,KAAK8E,QAAQ+F,kCAAoCJ,EACjDzK,KAAK8E,QAAQgG,SAAWJ,CA1CxB,CA2CJ,GAAC,CAAA/J,IAAA,4BAAAC,MAED,SAA0BmK,GACtB,GAAK/K,KAAKsG,YAAV,CAIA,IAAQ8C,EAA6D2B,EAA7D3B,sBAAuBE,EAAsCyB,EAAtCzB,sBAAuBC,EAAewB,EAAfxB,WAGhDyB,EAAgB,IAAI1G,EAAgB,CACtCO,KAAM,OACN/G,OAAQkC,KAAKlC,OACbc,KAAMoB,KAAK8E,QAAQmB,KACnB1B,OAAQvE,KAAK8E,QAAQ9G,aACrBwG,SAAUxE,KAAK8E,QAAQ6F,qBACvBlG,UAAWzE,KAAK8E,QAAQgG,SACxBpL,MAAO4J,EACP3E,MAAO4E,EACP3J,eAAgBI,KAAKJ,iBAInBqL,EAAgB,IAAI3G,EAAgB,CACtCO,KAAM,OACN/G,OAAQkC,KAAKlC,OACbc,KAAMoB,KAAK8E,QAAQmB,KACnB1B,OAAQvE,KAAK8E,QAAQ8F,0BACrBpG,SAAUxE,KAAK8E,QAAQ+F,kCACvBpG,UAAWzE,KAAK8E,QAAQgG,SACxBpL,MAAO0J,EACPxJ,eAAgBI,KAAKJ,iBAGnBsL,EAA8BlL,KAAK2J,gBAAgBzK,OAAS,EAElE,GAAI+L,EAAchL,sBAAwB+K,EAAc1K,UAAUpB,QAAU8L,EAAc/K,sBAAwBiL,EAG9G,OAFAC,QAAQC,KAAI,6FACZpL,KAAKsG,aAAc,GAKvB,IAAM+E,EAAiB,IAAI/G,EAAgB,CACvCO,KAAM,QACN/G,OAAQkC,KAAKlC,OACbc,KAAMoB,KAAK8E,QAAQmB,KACnBzB,SAAUxE,KAAK8E,QAAQ6F,qBACvBpG,OAAQvE,KAAK8E,QAAQ9G,aACrByG,UAAWzE,KAAK8E,QAAQgG,SACxBpL,MAAOwL,EACPtL,eAAgB/B,EAA2BmC,KAAKlC,OAAQoN,KAG5DlL,KAAK+G,QAAQuE,UAAY,CACrBC,MAAOF,EACPG,KAAMP,EACNQ,KAAMT,EApDV,CAsDJ,GAAC,CAAArK,IAAA,4BAAAC,MAED,SAA0ByH,EAAQE,EAAUJ,GACxC,IAAMjH,EAAkBlB,KAAKlC,OAAOqD,sBAAsB,CACtDxC,MAAO,uBACPyC,QACI,CAAA,CACIC,QAAS,EACTC,WAAYC,eAAeC,QAC3BC,OAAQ,CAAEC,KAAM1B,KAAKwG,cAAgB,UAAY,sBAErD,CACInF,QAAS,EACTC,WAAYC,eAAeC,QAC3BC,OAAQ,CAAEC,KAAM,YAEpB,CACIL,QAAS,EACTC,WAAYC,eAAeC,QAC3BC,OAAQ,CAAEC,KAAM,aACnBrB,OAAA+E,EACGpF,KAAKwG,eAAiBxG,KAAK6G,WAAa,CAAC,CACzCxF,QAAS,EACTC,WAAYC,eAAeC,QAC3BC,OAAQ,CAAEC,KAAM,aACf,OAIPC,EAAY3B,KAAKlC,OAAO8D,gBAAgB,CAC1CC,OAAQX,EACRE,QACI,CAAA,CACIC,QAAS,EACTS,SAAU,CAAEL,OAAQ4G,IAExB,CACIhH,QAAS,EACTS,SAAU,CAAEL,OAAQzB,KAAK8E,QAAQsF,iBAErC,CACI/I,QAAS,EACTS,SAAU,CAAEL,OAAQzB,KAAK8E,QAAQmE,kBACpC5I,OAAA+E,EAEGpF,KAAKwG,eAAiBxG,KAAK6G,WAAa,CAAC,CACzCxF,QAAS,EACTS,SAAU,CAAEL,OAAQ8G,KACnB,OAIPxG,EAAiB/B,KAAKlC,OAAOkE,qBAAqB,CACpDC,iBAAkB,CAAEf,KAoBxB,MAAO,CACH4B,SAlBqB9C,KAAKlC,OAAOqE,sBAAsB,CACvDxD,MAAO,uBACPkD,OAAQE,EACRK,QAAS,CACLC,OAAQrC,KAAK8G,cAAca,SAC3BrF,WAAY,aACZC,UAAW,CACPC,iBAAoBxC,KAAKJ,eAAe3B,EACxCwE,iBAAoBzC,KAAKJ,eAAe1B,EACxCwN,gBAAmB1L,KAAKjC,gBACxB2E,sBAAyB1C,KAAKC,sBAC9B2C,cAAiB5C,KAAKN,MACtBiM,YAAexD,MAOvBxG,UAAAA,EAER,GAAC,CAAAhB,IAAA,0BAAAC,MAED,SAAwByH,EAAQE,EAAUE,EAASC,EAAWP,GAC1D,IAAMjH,EAAkBlB,KAAKlC,OAAOqD,sBAAsB,CACtDxC,MAAO,qBACPyC,QACI,CAAA,CACIC,QAAS,EACTC,WAAYC,eAAeC,QAC3BC,OAAQ,CAAEC,KAAM,sBAEpB,CACIL,QAAS,EACTC,WAAYC,eAAeC,QAC3BC,OAAQ,CAAEC,KAAM,YAEpB,CACIL,QAAS,EACTC,WAAYC,eAAeC,QAC3BC,OAAQ,CAAEC,KAAM,sBAEpB,CACIL,QAAS,EACTC,WAAYC,eAAeC,QAC3BC,OAAQ,CAAEC,KAAM,uBACnBrB,OAAA+E,EACGpF,KAAK6G,WAAa,CAClB,CACIxF,QAAS,EACTC,WAAYC,eAAeC,QAC3BC,OAAQ,CAAEC,KAAM,sBAEpB,CACIL,QAAS,EACTC,WAAYC,eAAeC,QAC3BC,OAAQ,CAAEC,KAAM,aAEpB,OAINC,EAAY3B,KAAKlC,OAAO8D,gBAAgB,CAC1CC,OAAQX,EACRE,QACI,CAAA,CACIC,QAAS,EACTS,SAAU,CAAEL,OAAQ4G,IAExB,CACIhH,QAAS,EACTS,SAAU,CAAEL,OAAQgH,IAExB,CACIpH,QAAS,EACTS,SAAU,CAAEL,OAAQzB,KAAK8E,QAAQsF,iBAErC,CACI/I,QAAS,EACTS,SAAU,CAAEL,OAAQzB,KAAK8E,QAAQmE,kBACpC5I,OAAA+E,EACGpF,KAAK6G,WAAa,CAClB,CACIxF,QAAS,EACTS,SAAU,CAAEL,OAAQ8G,IAExB,CACIlH,QAAS,EACTS,SAAU,CAAEL,OAAQiH,KAExB,OAIN3G,EAAiB/B,KAAKlC,OAAOkE,qBAAqB,CACpDC,iBAAkB,CAAEf,KAoBxB,MAAO,CACH4B,SAlBoB9C,KAAKlC,OAAOqE,sBAAsB,CACtDxD,MAAO,qBACPkD,OAAQE,EACRK,QAAS,CACLC,OAAQrC,KAAK8G,cAAcc,QAC3BtF,WAAY,qBACZC,UAAW,CACPC,iBAAoBxC,KAAKJ,eAAe3B,EACxCwE,iBAAoBzC,KAAKJ,eAAe1B,EACxCwN,gBAAmB1L,KAAKjC,gBACxB2E,sBAAyB1C,KAAKC,sBAC9B2C,cAAiB5C,KAAKN,MACtBiM,YAAexD,MAOvBxG,UAAAA,EAER,GAEA,CAAAhB,IAAA,WAAAC,MAKA,SAASsC,GACAlD,KAAKsG,YAINsF,EAAA9F,EAAA9F,KAAK6L,GAA0BC,KAA/B9L,KAAgCkD,GAHhC0I,EAAA9F,EAAA9F,KAAK+L,GAAkBD,KAAvB9L,KAAwBkD,EAKhC,IAAC,CArfgB,GAqfhB,SAAA6I,EAKkB7I,GACf,IAAK,IAAIK,EAAI,EAAGA,EAAIvD,KAAKoG,UAAY,EAAG7C,IAAK,CACzC,IAAAC,EAA8CxD,KAAKM,UAAUiD,GAArDR,EAAgBS,EAAhBT,iBAAkB6F,EAAepF,EAAfoF,gBAG1B1F,EAAKO,YAAYV,EAAiBD,UAClCI,EAAKQ,aAAa,EAAGX,EAAiBpB,WACtCuB,EAAKS,mBAAmB3D,KAAKhC,aAAaC,EAAG+B,KAAKhC,aAAaE,EAAG,GAGlE8B,KAAK+G,QAAQiC,UAAUgD,SAAS9I,GAGhCA,EAAKO,YAAYmF,EAAgB9F,UACjCI,EAAKQ,aAAa,EAAGkF,EAAgBjH,WACrCuB,EAAKS,mBAAmB3D,KAAKhC,aAAaC,EAAG+B,KAAKhC,aAAaE,EAAG,EACtE,CACJ,CAEA,SAAA2N,EAG2B3I,GAEvBlD,KAAK+G,QAAQuE,UAAUC,MAAMS,SAAS9I,GAEtC,IAAK,IAAIK,EAAI,EAAGA,EAAIvD,KAAKoG,UAAY,EAAG7C,IAAK,CACzC,IAAA0I,EAA8CjM,KAAKM,UAAUiD,GAArDR,EAAgBkJ,EAAhBlJ,iBAAkB6F,EAAeqD,EAAfrD,gBAEtBrF,EAAI,GAAK,IAETvD,KAAK+G,QAAQuE,UAAUE,KAAKQ,SAAS9I,EAAMlD,KAAK8E,QAAQ9G,aAAcgC,KAAK6J,gBAAgBE,iBAC3F/J,KAAK+G,QAAQuE,UAAUG,KAAKO,SAAS9I,EAAMlD,KAAK8E,QAAQ8F,4BAI5D1H,EAAKO,YAAYV,EAAiBD,UAClCI,EAAKQ,aAAa,EAAGX,EAAiBpB,WACtCuB,EAAKU,2BAA2B5D,KAAK8E,QAAQ9G,aAAcgC,KAAK6J,gBAAgBC,YAGhF9J,KAAK+G,QAAQiC,UAAUgD,SAAS9I,EAAMlD,KAAK8E,QAAQ9G,aAAcgC,KAAK6J,gBAAgBG,YAGtF9G,EAAKO,YAAYmF,EAAgB9F,UACjCI,EAAKQ,aAAa,EAAGkF,EAAgBjH,WACrCuB,EAAKU,2BAA2B5D,KAAK8E,QAAQ9G,aAAcgC,KAAK6J,gBAAgBC,WACpF,CACJ"}